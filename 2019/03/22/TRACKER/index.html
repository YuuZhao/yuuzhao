<!DOCTYPE html>




<html class="theme-next gemini" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/head-icon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/headicon-32.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/headicon-16.png?v=5.1.3">


  <link rel="mask-icon" href="/images/head-icon.png?v=5.1.3" color="#222">





  <meta name="keywords" content="TRACKER,">





  <link rel="alternate" href="/atom.xml" title="yuuzhao" type="application/atom+xml">






<meta name="description" content="目标跟踪方法调研经典算法 前几名：Struck, SCM, ASLA，CSK, L1APG   OAB 2006 IVT 2008 MIL 2009 TLD 2010 STRUCK 2011 CT 2012 SCM 2012  目标跟踪面临的难点 外观变形 光照变化 快速运动 运动模糊 背景相似干扰 我的思考  相同的目标同时出现   平面外旋转  平面内旋转 尺度变化 遮挡和离开视野  目前常用">
<meta name="keywords" content="TRACKER">
<meta property="og:type" content="article">
<meta property="og:title" content="Tracker">
<meta property="og:url" content="http://yoursite.com/2019/03/22/TRACKER/index.html">
<meta property="og:site_name" content="yuuzhao">
<meta property="og:description" content="目标跟踪方法调研经典算法 前几名：Struck, SCM, ASLA，CSK, L1APG   OAB 2006 IVT 2008 MIL 2009 TLD 2010 STRUCK 2011 CT 2012 SCM 2012  目标跟踪面临的难点 外观变形 光照变化 快速运动 运动模糊 背景相似干扰 我的思考  相同的目标同时出现   平面外旋转  平面内旋转 尺度变化 遮挡和离开视野  目前常用">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/1.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/2.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/3.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/4.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/6.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/5.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/7.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/8.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/9.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/10.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/11.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/12.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/13.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/15.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/14.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/16.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/17.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/18.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/19.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/21.png">
<meta property="og:image" content="http://yoursite.com/2019/03/22/TRACKER/22.png">
<meta property="og:updated_time" content="2019-03-22T15:43:24.639Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tracker">
<meta name="twitter:description" content="目标跟踪方法调研经典算法 前几名：Struck, SCM, ASLA，CSK, L1APG   OAB 2006 IVT 2008 MIL 2009 TLD 2010 STRUCK 2011 CT 2012 SCM 2012  目标跟踪面临的难点 外观变形 光照变化 快速运动 运动模糊 背景相似干扰 我的思考  相同的目标同时出现   平面外旋转  平面内旋转 尺度变化 遮挡和离开视野  目前常用">
<meta name="twitter:image" content="http://yoursite.com/2019/03/22/TRACKER/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/03/22/TRACKER/">





  <title>Tracker | yuuzhao</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?5469094107eb88f91cbb80b4256365fb";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">yuuzhao</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Yuyu Zhao's Personal Website</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/22/TRACKER/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yuyu Zhao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="yuuzhao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Tracker</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-22T17:14:01+08:00">
                2019-03-22
              </time>
            

            

            
			
          </span>
		  
			
				<span class="post-visit-count">
					&nbsp; | &nbsp; 
					<!--眼睛图标-->
					<i class="fa fa-eye"></i>&nbsp;
					<span id="detail_cnt">1</span>
				</span>
			
			
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/22/TRACKER/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/03/22/TRACKER/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="目标跟踪方法调研"><a href="#目标跟踪方法调研" class="headerlink" title="目标跟踪方法调研"></a>目标跟踪方法调研</h1><h2 id="经典算法"><a href="#经典算法" class="headerlink" title="经典算法"></a>经典算法</h2><ul>
<li>前几名：Struck, SCM, ASLA，CSK, L1APG</li>
<li><img src="/2019/03/22/TRACKER/1.png" alt=""></li>
<li><img src="/2019/03/22/TRACKER/2.png" alt=""></li>
<li>OAB 2006</li>
<li>IVT 2008</li>
<li>MIL 2009</li>
<li>TLD 2010</li>
<li>STRUCK 2011</li>
<li>CT 2012</li>
<li>SCM 2012</li>
</ul>
<h2 id="目标跟踪面临的难点"><a href="#目标跟踪面临的难点" class="headerlink" title="目标跟踪面临的难点"></a>目标跟踪面临的难点</h2><ul>
<li>外观变形</li>
<li>光照变化</li>
<li>快速运动</li>
<li>运动模糊</li>
<li>背景相似干扰</li>
<li><p>我的思考</p>
<ul>
<li>相同的目标同时出现</li>
</ul>
</li>
<li><p>平面外旋转</p>
</li>
<li>平面内旋转</li>
<li>尺度变化</li>
<li>遮挡和离开视野</li>
</ul>
<h2 id="目前常用数据库"><a href="#目前常用数据库" class="headerlink" title="目前常用数据库"></a>目前常用数据库</h2><ul>
<li><p>OTB</p>
<ul>
<li>OTB包括25%的灰度序列</li>
<li>随机帧开始，或矩形框加随机干扰初始化</li>
</ul>
</li>
<li><p>VOT</p>
<ul>
<li>但VOT都是彩色序列，这也是造成很多颜色特征算法性能差异的原因</li>
<li>VOT库的序列分辨率普遍较高</li>
<li>VOT是第一帧初始化去跑，每次跟踪失败(预测框和标注框不重叠)时，5帧之后再次初始化</li>
<li>VOT2016，因为序列都是精细标注，且评价指标我更加认可(</li>
</ul>
</li>
</ul>
<h2 id="目标视觉跟踪方法分类"><a href="#目标视觉跟踪方法分类" class="headerlink" title="目标视觉跟踪方法分类"></a>目标视觉跟踪方法分类</h2><ul>
<li><p>生成模型方法</p>
<ul>
<li>在当前帧对目标区域建模，下一帧寻找与模型最相似的区域就是预测位置</li>
<li><p>著名方法</p>
<ul>
<li>卡尔曼滤波</li>
<li>粒子滤波</li>
<li>mean-shift</li>
</ul>
</li>
<li><p>举个例子，从当前帧知道了目标区域80%是红色，20%是绿色，然后在下一帧，搜索算法就像无头苍蝇，到处去找最符合这个颜色比例的区域</p>
</li>
<li><p>推荐算法ASMS</p>
<ul>
<li><a href="https://github.com/vojirt/asms" target="_blank" rel="noopener">https://github.com/vojirt/asms</a></li>
<li>VOT2015的第20名，官方推荐的实时算法，VOT2016的32名，平均帧率125FPS，在经典mean-shift框架下加入了尺度估计，经典颜色直方图特征，加入了两个先验(尺度不剧变+可能偏最大)作为正则项，和反向尺度一致性检查，作者给了C++代码，在相关滤波和深度学习盛行的年代，还能看到mean-shift打榜，如此高的性价比实在不容易(已泪目~~)，实测性能还不错。</li>
</ul>
</li>
</ul>
</li>
<li><p>判别模型方法</p>
<ul>
<li>又叫检测跟踪tracking-by-detection</li>
<li>经典套路图像特征+机器学习</li>
<li><p>当前帧以目标区域为正样本，背景区域为负样本，机器学习训练分类器，下一帧用训练好的分类器找最优区域</p>
<ul>
<li><img src="/2019/03/22/TRACKER/3.png" alt=""></li>
</ul>
</li>
<li><p>分类器训练过程中用到了背景信息，这样分类器专注区分前景和背景，判别类方法普遍都比生成类好</p>
</li>
<li><p>相关滤波类方法</p>
<ul>
<li>别看那些五花八门的机器学习方法，那都是虚的，目标跟踪算法中特征才是最重要的。,对于那些仅简单修改机器学习方法而不关注如何减小边界效应的相关滤波，也许可能大概会有效果，</li>
</ul>
</li>
<li><p>深度学习(Deep ConvNet based)类方法</p>
<ul>
<li><p>MDNet</p>
<ul>
<li><a href="http://cvlab.postech.ac.kr/research/mdnet/" target="_blank" rel="noopener">http://cvlab.postech.ac.kr/research/mdnet/</a></li>
</ul>
</li>
<li><p>TCNN</p>
<ul>
<li><a href="http://www.votchallenge.net/vot2016/download/44_TCNN.zip" target="_blank" rel="noopener">http://www.votchallenge.net/vot2016/download/44_TCNN.zip</a></li>
</ul>
</li>
<li><p>SiamFC</p>
<ul>
<li><a href="http://www.robots.ox.ac.uk/~luca/siamese-fc.html" target="_blank" rel="noopener">www.robots.ox.ac.uk/~luca/siamese-fc.html</a></li>
</ul>
</li>
<li><p>SiamFC-R</p>
<ul>
<li><a href="http://www.iqiyi.com/w_19ruirwrel.html#vfrm=8-8-0-1" target="_blank" rel="noopener">http://www.iqiyi.com/w_19ruirwrel.html#vfrm=8-8-0-1</a></li>
</ul>
</li>
<li><p>GOTURN</p>
<ul>
<li><a href="https://github.com/davheld/GOTURN" target="_blank" rel="noopener">https://github.com/davheld/GOTURN</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="基于孪生网络的方法汇总"><a href="#基于孪生网络的方法汇总" class="headerlink" title="基于孪生网络的方法汇总"></a>基于孪生网络的方法汇总</h2><ul>
<li><img src="/2019/03/22/TRACKER/4.png" alt="Recent Tracher develop"></li>
<li><p>SINT</p>
<ul>
<li><p>首次开创性的将目标跟踪问题转化为一个patch块匹配问题，并神经网络来实现。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/6.png" alt="SINT"></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取ALOV数据集，并进行预处理；</li>
<li><p>步骤2：搭建如图所示的类似AlexNet的网络架构（引入ROI Pooling层）；</p>
<ul>
<li><img src="/2019/03/22/TRACKER/5.png" alt="SINT"></li>
</ul>
</li>
<li><p>步骤3：在训练数据中获取patch块，开始训练网络，获得最终的模型，即所谓的相似度函数；</p>
</li>
<li>步骤4：使用预训练好的网络进行跟踪，即所谓的patch块匹配，输出相应的结果。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1- 创造性的将目标跟踪任务转化为patch块匹配问题；</li>
<li>创新2-设计了相应的网络架构，尝试着去解决这个问题；</li>
</ul>
</li>
</ul>
</li>
<li><p>Siamese-fc</p>
<ul>
<li><p>这个框图与众不同的是它是一个端到端的跟踪网络，而且速度很快！这篇论文使得基于孪生网络的跟踪器火了起来，让研究者们看到了新的希望。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/7.png" alt=""></li>
</ul>
</li>
<li><p>算法实现步骤</p>
<ul>
<li>步骤1：获取VID数据集，并进行预处理操作获得相应的patch块数据；</li>
<li>步骤2：将获取的patch数据输入到上图所示的网络架构中进行训练，从而获得最终的模型；</li>
<li>步骤3：将训练好的模型分别应用在视频中的第一帧和后续帧中，通过相关操作获得最终的结果；</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-设计了一个端到端的跟踪网络；</li>
<li>创新2-获得了一个很快的跟踪速度，Titan xp 58fps；</li>
<li>创新3-使用了一个更大的数据集来训练网络；</li>
<li>创新4-提到了很多关键的细节，包括网络中padding的影响，以及网络输入的大小等。</li>
</ul>
</li>
</ul>
</li>
<li><p>CFNet</p>
<ul>
<li><p>这篇文章整体思路和Siamese-fc算法的思路基本相同，不同之处在于将相关滤波（CF）整合为一个网络层，并将其嵌入到基于孪生网络的框架中，如图中蓝色的区域所示。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/8.png" alt=""></li>
</ul>
</li>
<li><p>步骤同上</p>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-将相关滤波操作变成了一个单一的网络层，并嵌入到网络中；</li>
<li>创新2-调整了网络的架构，比如输入等；</li>
<li>创新3-向我们展示了严格的理论推导过程，值得去学习！！！</li>
</ul>
</li>
</ul>
</li>
<li><p>DSiam</p>
<ul>
<li><blockquote>
<p>论文：<br><a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2017/papers/Guo_Learning_Dynamic_Siamese_ICCV_2017_paper.pdf</a><br>代码：<a href="https://github.com/tsingqguo/DSiam" target="_blank" rel="noopener">https://github.com/tsingqguo/DSiam</a></p>
</blockquote>
</li>
<li><p>该算法在siamese-fc框架的基础上面添加了目标外观变换转换层和背景抑制变换层来提升网络的判别能力，即增强了模型在线更新的能力。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/9.png" alt=""></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取ILSVC-2015数据集（又名VID），并进行预处理操作；</li>
<li>步骤2：搭建如上图所示的网络模型，引入了circular convolution (‘CirConv’) and regularized linear regression (‘RLR’)层，进行模型的训练过程；</li>
<li>步骤3：将预训练好的模型分别应用在第一帧和后续帧中，并进行模型在线更新操作，通过相关操作获取对应的得分映射，得到最终的结果。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-为了提升模型的泛化能力，分别在x和z分支中外观变化转换层和背景抑制转换层；</li>
<li>创新2-尝试着融合基准网络的不同层；</li>
<li>创新3-严格的理论推导，值得学习。</li>
</ul>
</li>
</ul>
</li>
<li><p>SINT++</p>
<ul>
<li>论文：<br><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SINT_Robust_Visual_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_SINT_Robust_Visual_CVPR_2018_paper.pdf</a><br>项目：<br><a href="https://sites.google.com/view/cvpr2018sintplusplus/" target="_blank" rel="noopener">https://sites.google.com/view/cvpr2018sintplusplus/</a><br>Poster：<br><a href="https://drive.google.com/file/d/1Tn-WkOM3gkCX7Upp5X-YELxUbLAE3o8a/view?usp=sharing" target="_blank" rel="noopener">https://drive.google.com/file/d/1Tn-WkOM3gkCX7Upp5X-YELxUbLAE3o8a/view?usp=sharing</a></li>
<li><p>这篇文章是SINT算法的改进版，主要的改进部分如图中篮框所示，目的是为了生成多样性的输入正样本块，使用到了AE(AutoEncoder)和GAN网络。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/10.png" alt=""></li>
</ul>
</li>
<li><p>算法实现步骤</p>
<ul>
<li>步骤1：分别从VOT-2013、VOT-2014和VOT-2016中收集一部分数据集，进行预处理操作；</li>
<li>步骤2：将获取到的训练集依次输入到正样本块生成网络和正样本块转换网络中去生成多样性的这样本块；</li>
<li>步骤3：将获取的样本块输入到SINT网络中进行训练，获得相应的网络模型；</li>
<li>步骤4：将整个预训练网络分别应用在第一帧和后续帧中，获取最终的结果。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-使用PSGN网络获得多样性的样本图像，从而提升了算法的鲁棒性；</li>
<li>创新2-使用HPTN网络来处理目标遮挡问题，提升算法的鲁棒性；</li>
<li>创新3-将AE和GAN这种比较热的概念应用到跟踪算法中，即所谓的应用创新。</li>
</ul>
</li>
</ul>
</li>
<li><p>SA-Siam</p>
<ul>
<li><p>该算法中的主要改动如图中绿框所示，即双网络分别学习不同的特征、在Z分支添加注意力机制和多层特征的融合。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/11.png" alt=""></li>
</ul>
</li>
<li><p>论文：<br><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/He_A_Twofold_Siamese_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/He_A_Twofold_Siamese_CVPR_2018_paper.pdf</a></p>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取ILSVRC-2015中的彩色图片作为训练集，进行预处理操作；</li>
<li>步骤2：利用训练集数据分别训练两个不同的网络分支，即A-Net和S-Net，获得相应的网络模型；</li>
<li>步骤3：将整个网络整合在一起并将其应用在视频中获取相应的得分映射图；</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-使用两个网络分别获取网络的语义特征和外观特征；</li>
<li>创新2-对两个分支网络进行单独训练；</li>
<li>创新3-在语义分支网络中使用了注意力机制和特征融合；</li>
</ul>
</li>
</ul>
</li>
<li><p>RASNet</p>
<ul>
<li><p>该算法中最大的特色是将Attention机制应用的淋漓尽致，使用到了3个注意力机制，包括残差注意力块，通道注意力块和通用注意力块。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/12.png" alt=""></li>
</ul>
</li>
<li><p>通过注意力机制可以使得整个网络可以根据目标的变化而自适应的进行调整。</p>
</li>
<li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Attentions_Residual_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Learning_Attentions_Residual_CVPR_2018_paper.pdf</a></li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取ILSVRC15数据集作为训练集，并进行数据预处理操作；</li>
<li>步骤2：搭建如上图所示的网络架构，分别训练获得残差注意力块和通道注意力块；</li>
<li>步骤3：将预训练的注意力模块应用到视频中，进行相关操作获得最终的结果。</li>
</ul>
</li>
<li><p>创新</p>
<ul>
<li>创新1-多个注意力机制使得网络不需要进行在线更新操作，其实更新操作换做注意力机制来做！</li>
<li>创新2-通过残差注意力机制和通道注意力机制在缓解网络过拟合的同时提升网络的判别能力；</li>
<li>创新3-考虑到视频中的时空信息，并通道注意力机制来获得。</li>
</ul>
</li>
</ul>
</li>
<li><p>SiamRPN</p>
<ul>
<li>论文：<br><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf</a><br>项目：<a href="http://bo-li.info/SiamRPN/" target="_blank" rel="noopener">http://bo-li.info/SiamRPN/</a><br>代码(PyTorch)：<br><a href="https://github.com/songdejia/Siamese-RPN-pytorch" target="_blank" rel="noopener">https://github.com/songdejia/Siamese-RPN-pytorch</a><br>代码(TensorFlow)：<br><a href="https://github.com/makalo/Siamese-RPN-tensorflow" target="_blank" rel="noopener">https://github.com/makalo/Siamese-RPN-tensorflow</a></li>
<li><p>将目标检测中的RPN模块应用到跟踪任务中来，即如图中绿色区域的分类和回归分支，由于回归分支的存在使得该算法可以去掉原始的尺度金字塔，因此该算法在提升精度的同时达到的提速。将原始的相似度计算问题转化为回归和分类问题。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/13.png" alt=""></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取VID和 Youtube-BB数据集作为训练数据集，并进行数据预处理；</li>
<li>步骤2：搭建如上图所示的网络框架，同时进行分类分支和回归分支的训练，获得网络模型；</li>
<li>步骤3：应用预训练的模型到视频中通过分类和回归操作初步获得目标；</li>
<li>步骤4：使用NMS等多个tricks进行后处理操作，获得最终的目标。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-将RPN的思路应用到跟踪领域中，在提速的同时提升了精度；</li>
<li>创新2-引入1x1卷积层来对网络的通道进行升维处理；</li>
<li>创新3-尝试着去使用更大的数据集，光Youtube-BB就几千个视频序列，所以数据也是至关重要的！！</li>
<li>创新4-使得基于孪生网络的跟踪算法的性能有了大幅度的提升，让我们看到了希望！！！</li>
</ul>
</li>
</ul>
</li>
<li><p>SiamFC-tri</p>
<ul>
<li>论文：<br><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Xingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/Xingping_Dong_Triplet_Loss_with_ECCV_2018_paper.pdf</a><br>代码：<br><a href="https://github.com/shenjianbing/TripletTracking" target="_blank" rel="noopener">https://github.com/shenjianbing/TripletTracking</a></li>
<li><p>该文的主要工作是将孪生网络领域中使用广泛的triplet loss应用到跟踪问题上来，可以说是一个应用创新。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/15.png" alt=""></li>
</ul>
</li>
<li><p>实现步骤和siamese-fc基本类似，增加了triplet分支块。</p>
</li>
</ul>
</li>
<li><p>StructSiam</p>
<ul>
<li><p>框架</p>
<ul>
<li><img src="/2019/03/22/TRACKER/14.png" alt=""></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取ILSVRC VID数据集作为训练集，并进行预处理操作；</li>
<li>步骤2：搭建如上图所示的网络框架，需要关注的是局部模式检测层和纹理模型的构建，从而获得相应的模型；</li>
<li>步骤3：使用预训练模型通过相关操作获得一个更准确的得分映射图；</li>
<li>步骤4：进行后续的加窗等后处理操作；</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-使用局部结构学习方法来减缓模型对非刚体运动变化的敏感程度；</li>
<li>创新2-通过多个局部结构块的任意组合可以形成更丰富的纹理；</li>
<li>创新3-将相似性比较问题转化为一个局部特征块的比较问题。</li>
</ul>
</li>
</ul>
</li>
<li><p>DaSiamRPN</p>
<ul>
<li>论文：<br><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Zheng_Zhu_Distractor-aware_Siamese_Networks_ECCV_2018_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ECCV_2018/papers/Zheng_Zhu_Distractor-aware_Siamese_Networks_ECCV_2018_paper.pdf</a><br>Silde：<br><a href="https://drive.google.com/file/d/1dsEI2uYHDfELK0CW2xgv7R4QdCs6lwfr/view" target="_blank" rel="noopener">https://drive.google.com/file/d/1dsEI2uYHDfELK0CW2xgv7R4QdCs6lwfr/view</a><br>代码：<br><a href="https://github.com/foolwood/DaSiamRPN" target="_blank" rel="noopener">https://github.com/foolwood/DaSiamRPN</a></li>
<li><p>该论文是对SiamRPN论文的初步改进版，主要解决的问题是正负样本块不均衡问题和样本块的丰富性问题，即更关注于输入数据的问题。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/16.png" alt=""></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>创新1-发现训练正负样本块不均衡问题会影响网络判别相似目标的能力，不如两个穿着黄色衣服的人；</li>
<li>创新2-引入一个高效的采样策略来解决该问题；</li>
<li>创新3-引入一个局部到全局的搜索策略来解决long-term跟踪问题，这个问题正在变得越来越重要！！！</li>
</ul>
</li>
</ul>
</li>
<li><p>DenseSiam</p>
<ul>
<li><p>论文：<a href="https://arxiv.org/abs/1809.02714" target="_blank" rel="noopener">https://arxiv.org/abs/1809.02714</a><br>代码：<br><a href="http://www.votchallenge.net/vot2018/trackers.html" target="_blank" rel="noopener">http://www.votchallenge.net/vot2018/trackers.html</a></p>
</li>
<li><p>该论文主要工作是将Dense-Block应用到跟踪网络中来，是一个类似于残差块的东西，不过它是密集型链接，该思路借鉴于图像分类，同时在目标图像分支增加了注意力模块提升模型的自适应能力。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/17.png" alt=""></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取ILSVRC1数据集作为训练数据集，进行数据预处理操作；</li>
<li>步骤2：搭建如上图所示的网络，关注于Dense=Block块的搭建细节和注意力机制的实现细节，获得网络模型；</li>
<li>步骤3：将预训练的模型应用到视频中获取一个好的score_map，获得初步结果；</li>
<li>步骤4：进行加窗等后处理操作获得最终结果。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-使用Dense-Block来获取更鲁棒的特征表示；</li>
<li>创新2-构建了一个相对于AlexNet网络更深的一个网络；</li>
<li>创新3-添加注意力机制来提升得分相应的效果。</li>
</ul>
</li>
</ul>
</li>
<li><p>Siam-BM</p>
<ul>
<li><p>主要思路是通过角度评估模块和空间mask模块分别来解决目标的大尺度旋转和网络区分相似目标的能力。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/18.png" alt=""></li>
</ul>
</li>
<li><p>论文：<a href="https://arxiv.org/abs/1809.01368" target="_blank" rel="noopener">https://arxiv.org/abs/1809.01368</a><br>项目：<a href="https://77695.github.io/Siam-BM" target="_blank" rel="noopener">https://77695.github.io/Siam-BM</a><br>代码：<a href="https://github.com/77695/Siam-BM" target="_blank" rel="noopener">https://github.com/77695/Siam-BM</a></p>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取ILSVRC-2015数据集中的彩色图片作为训练集，并进行预处理操作；</li>
<li>步骤2：构建上图的网络主要关注角度评估块和mask模块的构造，获得最终的网络模型；</li>
<li>步骤3：将预训练的模型应用到视频中，获取多个可能的得分映射图，选择最好的映射图作为初步结果；</li>
<li>步骤4：进行加窗等后处理操作，返回最终的结果。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-针对siamese-fc中没有考虑到的角度评估问题提出了解决方案，尽量不影响算法速度；</li>
<li>创新2-根据目标的比例选择出合适的mask来提升算法区分相似目标的能力；</li>
</ul>
</li>
</ul>
</li>
<li><p>C-RPN</p>
<ul>
<li><p>主要思路是为了区分相似的目标作者使用了堆叠SiamRPN的思路可以在网络的前期抑制掉一些比较简单的样本块，在后期的网路中可以获得更加具有代表性的样本块；同时通过多级的回归操作可以使得输出的BB更加准确，会在一定程度上提升算法的精度，其实目标检测中也有类似的算法。</p>
<ul>
<li><img src="/2019/03/22/TRACKER/19.png" alt=""></li>
<li>论文：<a href="https://arxiv.org/abs/1812.06148" target="_blank" rel="noopener">https://arxiv.org/abs/1812.06148</a></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：同时获取VID和YT-BB数据集作为训练集，并进行预处理操作；</li>
<li>步骤2：搭建如图所示的网络架构，首先训练第一阶段的SiamRPN，训练好之后接着训练下一个阶段的；</li>
<li>步骤3：使用特征转换模块将不同级的SiamRPN级联起来，使用最后的SiamRPN进行分类和回归，输出最终的结果。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>步骤1：同时获取VID和YT-BB数据集作为训练集，并进行预处理操作；</li>
<li>步骤2：搭建如图所示的网络架构，首先训练第一阶段的SiamRPN，训练好之后接着训练下一个阶段的；</li>
<li>步骤3：使用特征转换模块将不同级的SiamRPN级联起来，使用最后的SiamRPN进行分类和回归，输出最终的结果。</li>
</ul>
</li>
</ul>
</li>
<li><p>SiamMask</p>
</li>
</ul>
<pre><code>- 思路是在saimese-fc的基础上添加了mask分支，和mask-rcnn有异曲同工之妙，mask分支的存在使用检测的结果更加准确，同时该算法可以获取跟踪目标的BB和Mask，这在现实应用中有很多的用处！！！
    - 论文：https://arxiv.org/abs/1812.05050
    - 项目：http://www.robots.ox.ac.uk/~qwang/SiamMask/
    - 代码：http://www.robots.ox.ac.uk/~qwang/SiamMask/

    - ![](TRACKER/20.png)
- 步骤

    - 步骤1：获取COCO、ImageNet-VID 和YouTube-VOS数据集作为训练数据集，并进行预处理；
    - 步骤2：搭建如图所示的网络框架，关键在于RoW的引入和mask分支的实现，具体见论文，获得最终的模型；
    - 步骤3：将预训练的模型应用在视频中，同时获取待跟踪目标的BB和Mask信息。

- 创新点

    - 创新1-使用一个网络同时解决了视频目标跟踪和视频目标分割问题；
    - 创新2-通过mask分支来提升跟踪的效果；
    - 创新3-引入RoW模获得准确的mask;
    - 创新4-使用超大的数据集做训练，一般人是不敢用这么大的数据的，跑模型就需要很长时间，设备的差距！！！
</code></pre><ul>
<li><p>CIR</p>
<ul>
<li><p>放在后面的都是用来压轴的，这是CVPR2019的一篇oral，仔细去看看你就会发现视觉目标跟踪近几年的oral论文小的可怜，而这篇论文能够成为oral肯定是解决了视觉目标跟踪中的一个大问题吧！没错，如果你是做跟踪的，你可能会发现我前面讲的这些算法的baseline网络都是AlexNet网络！！！很多人好奇干嘛不用ResNet、Inception等深度网络呢?其实跟踪领域中的很多学者们都尝试着用ResNet作为基准网络，但是却发现直接使用深层网络后后跟踪效果反而变差！！！这令人百思不得其解，因此这是孪生网络跟踪器中一个很重要的问题，结果这篇论文给出了我们一个详细的答案，最主要的原因是因为ResNet网络中都会有Padding操作，而这个操作会影响算法的平移不变性，使得网络更加关注图像中心</p>
<ul>
<li>论文：<a href="https://arxiv.org/abs/1901.01660" target="_blank" rel="noopener">https://arxiv.org/abs/1901.01660</a></li>
<li>代码：<a href="https://gitlab.com/MSRA_NLPR/deeper_wider_siamese_trackers" target="_blank" rel="noopener">https://gitlab.com/MSRA_NLPR/deeper_wider_siamese_trackers</a></li>
<li><img src="/2019/03/22/TRACKER/21.png" alt=""></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：使用Siamese-fc或者SiamRPN的基本框架，我们仅仅将baseline网络更换成深层网络；</li>
<li>步骤2：针对ResNet中存在的pading问题加入了Crop层，思路即你既然会有影响我就把你去掉哈，思路及其简单去很有效果！</li>
<li>步骤3：作者设计了CIR和CIR-D块，然后通过堆叠这些块构建了深层网络，具体网络请看论文中；</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-深入的去探讨问题，而不是逃避问题，值得学习！！！</li>
<li>创新2-通过简单的Crop操作解决了一个关键的问题；</li>
<li>创新3-通过修改原始ResNet中的块构建出新的块；</li>
<li>创新4-论文中深刻的讨论了网络的输入大小、步长大小和padding操作的影响，并给出了合理的建议，这些建议有利于后续跟踪网络的自行设计！！！</li>
</ul>
</li>
</ul>
</li>
<li><p>SiamRPN++</p>
<ul>
<li><p>这也是CVPR2019中的一篇oral，而且是视觉目标跟踪的，所以看出跟踪在CVPR2019年有了很大的突破了，这是一个事实，后续会有更多优秀的论文投出，视觉目标跟踪距离真正的场景应用已经越来越近啦！！！这篇论文解决的第一个问题也是深层网络ResNet为何不能应用在孪生网络架构中提升性能！！！但是它提出了不同的方案，即作者发现原始的采样策略存在问题，原始的采样策略使得图像的中心一直有较大的权重，因此作者在中心进行移位，即偏移中心16-64个像素范围内进行均匀采样；而本文解决的另一个问题是相似目标的问题，对应的解决方案是抽取深度网络的多个特征层分别作分类和回归，并进行结果级联，思路和C-RPN很相似！！！</p>
<ul>
<li>论文：<a href="https://arxiv.org/abs/1812.11703" target="_blank" rel="noopener">https://arxiv.org/abs/1812.11703</a></li>
<li>项目：<a href="http://bo-li.info/SiamRPN++/" target="_blank" rel="noopener">http://bo-li.info/SiamRPN++/</a></li>
<li><img src="/2019/03/22/TRACKER/22.png" alt=""></li>
</ul>
</li>
<li><p>步骤</p>
<ul>
<li>步骤1：获取COCO 、ImageNet DET、 ImageNet VID和 YouTube-BoundingBoxes Dataset数据集来作为跟踪数据集，并进行预处理操作，数据集超级大！！！</li>
<li>步骤2：搭建上图所示的网络，去掉了ResNet中的两个降采样层，并分别对conv3、conv4和conv5的最后一层上面做分类和回归操做，网络的训练顺序也是依次训练；</li>
<li>步骤3：将预训练的网络应用到视频中，获得最终的分类和结果作为初步结果；</li>
<li>步骤4：进行后续的NMS等tricks后处理操作。</li>
</ul>
</li>
<li><p>创新点</p>
<ul>
<li>创新1-深刻的分析问题，理解问题的本质，并提出解决方案；</li>
<li>创新2-使用多级级联的思路获取鲁棒的特征表示；</li>
<li>创新3-在多个数据集中都是state-of-art结果；</li>
<li>创新4-使得基于孪生网络的跟踪器真正超越了基于相关滤波器的跟踪算法！！！</li>
</ul>
</li>
</ul>
</li>
<li><p>未来研究思路</p>
<ul>
<li>高效的在线学习算法：进展到目前为止，我的所有实验研究表明。Siamese 网络无法真正意义上抑制背景中的困难样本。离线的学习从本质上无法区分两个长相相似的人或者车。而 CF 相关算法可以通过分析整个环境的上下文关系来进行调整。如果对于提升整个算法的上界（偏学术）的角度考虑，在线学习有必要。如果正常的工程使用，我认为目前的算法只要在相应的场景中进行训练就足够了。</li>
<li>精确输出表达：今年我们的工作提出额外的 mask 输出。可直接扩展的思路为关键点输出（CornerNet / PoseTrack），极点预测（ExtremeNet），甚至 6D pose 跟踪。本质上是通过网络可以预测任何与目标相关的输出。大家可以任意的发散思维。</li>
<li>定制网络架构：其中包含两个子方向，一个是追求精度的去探索究竟什么样的网络架构会有利于当前的跟踪框架的学习。另一个有价值的子方向是如何构建超快速的小网络用于实际工程。工程项目中有时并没有 GPU 的资源供使用，如何提供 “廉价” 的高质量跟踪算法也具有很强的实际意义。当对网络进行裁剪之后，很容易达到 500FPS 的高性能算法来对传统的 KCF 进行真正的替换。</li>
<li>离线训练学习优化：目前的跟踪算法在相似性学习方向还是过于简单，如果去设计更为有效的度量学习方案，应该会有一定的提升。同时我们也并没有很好的掌握网络的训练。当前的训练策略是将网络主干的参数进行固定，先训练 head。然后逐步放开。实际上我们发现，当直接将所有层全部放开一起训练的时候，网络的泛化性能会显著下降。另一个方面，train from scratch 的概念已经在检测领域非常普遍了。跟踪的网络目前我们的经验在跟踪方面并不 work。</li>
<li>更细粒度预测：这一条实际上是上一条的续集，就是专注于 score 分支的预测。现在大家的做法是 &gt; 0.6 IoU 的都当做前景（正样本），但实际上正样本之间还是有较大的差异的。跟踪本质上也是不断预测一个非常细小物体帧间运动的过程，如果一个网络不能很好的分辨细小的差异，他可能并不是一个最优的设计选择。这也是 ATOM 的 IoUNet 主攻的方向。</li>
<li>泛化性能提升：非常推荐自动化所黄凯奇老师组的 GOT-10k 数据集，数据组织的非常棒。黄老师组在 one-shot learning 领域有着深厚的积淀，所以站在这个领域的角度，他们提出了严格分离训练集和测试集的物体类别来验证泛化性能。所以原则上所有 one-shot learning 方向的一些嵌入学习方法都可以移过来用。同时，我觉得 Mask-X-RCNN，segment everything 这个思路可以借鉴。本质上我也不得不承认，基于深度学习的跟踪算法存在泛化性能问题。我们有理由怀疑跟踪是否会在未知的类别上有较好的泛化性能，实际上肯定是会下降。</li>
<li>long-term 跟踪框架：截止到目前为止，虽然 VOT 组委会以及牛津这边的 OxUVA 都有专门的 long-term 的数据集，但 long-term 算法并没有一个较好的统一框架出来。关于这方面的研究似乎有点停滞，今年大连理工的文章非常可惜，我觉得质量非常不错。</li>
</ul>
</li>
</ul>
<p><em>XMind: ZEN - Trial Version</em></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/TRACKER/" rel="tag"># TRACKER</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/22/TLD/" rel="next" title="TLD">
                <i class="fa fa-chevron-left"></i> TLD
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Yuyu Zhao">
            
              <p class="site-author-name" itemprop="name">Yuyu Zhao</p>
              <p class="site-description motion-element" itemprop="description">The hardest choices require the strongest wills.</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#目标跟踪方法调研"><span class="nav-number">1.</span> <span class="nav-text">目标跟踪方法调研</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#经典算法"><span class="nav-number">1.1.</span> <span class="nav-text">经典算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目标跟踪面临的难点"><span class="nav-number">1.2.</span> <span class="nav-text">目标跟踪面临的难点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目前常用数据库"><span class="nav-number">1.3.</span> <span class="nav-text">目前常用数据库</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目标视觉跟踪方法分类"><span class="nav-number">1.4.</span> <span class="nav-text">目标视觉跟踪方法分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于孪生网络的方法汇总"><span class="nav-number">1.5.</span> <span class="nav-text">基于孪生网络的方法汇总</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuyu Zhao</span>

  
</div>










    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">Total Visits<span id="busuanzi_value_site_pv"></span>time</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">The Total Visitors<span id="busuanzi_value_site_uv"></span>population</span>
    <span class="post-meta-divider">|</span>




    


  <script src="https://cdn.firebase.com/js/client/2.0.4/firebase.js"></script>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  

    
      <script id="dsq-count-scr" src="https://yuuzhao.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2019/03/22/TRACKER/';
          this.page.identifier = '2019/03/22/TRACKER/';
          this.page.title = 'Tracker';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://yuuzhao.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
