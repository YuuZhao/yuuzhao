<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>yuuzhao</title>
  
  <subtitle>Yuyu Zhao&#39;s Personal Website</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-03-17T00:46:44.851Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Yuyu Zhao</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Plasticity Neural Networks</title>
    <link href="http://yoursite.com/2019/03/14/PLASTICITY-NEURAL-NETWORKS/"/>
    <id>http://yoursite.com/2019/03/14/PLASTICITY-NEURAL-NETWORKS/</id>
    <published>2019-03-14T12:48:55.000Z</published>
    <updated>2019-03-17T00:46:44.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Plastic-NN"><a href="#Plastic-NN" class="headerlink" title="Plastic NN"></a>Plastic NN</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h3 id="How-can-we-build-agents-that-keep-learning-from-experience-after-their-initial-training"><a href="#How-can-we-build-agents-that-keep-learning-from-experience-after-their-initial-training" class="headerlink" title="How can we build  agents that keep learning from experience , after their initial training ?"></a>How can we build  agents that keep learning from experience , after their initial training ?</h3><h3 id="Take-inspiration-from-the-main-mechanism-of-learning-in-biological-brains-synaptic-plasticity"><a href="#Take-inspiration-from-the-main-mechanism-of-learning-in-biological-brains-synaptic-plasticity" class="headerlink" title="Take inspiration from the main mechanism of learning in biological brains : synaptic plasticity"></a>Take inspiration from the main mechanism of learning in biological brains : synaptic plasticity</h3><h3 id="Synaptic-plasticity-carefully-tuned-by-evolution-to-produce-efficient-lifelong-learning"><a href="#Synaptic-plasticity-carefully-tuned-by-evolution-to-produce-efficient-lifelong-learning" class="headerlink" title="Synaptic plasticity , carefully tuned by evolution to produce efficient lifelong learning ."></a>Synaptic plasticity , carefully tuned by evolution to produce efficient lifelong learning .</h3><h3 id="we-show-that-plasticity-just-like-connection-weights-can-be-optimized-by-gradient-descent-in-large-recurrent-networks-with-hebbian-plastic-connections"><a href="#we-show-that-plasticity-just-like-connection-weights-can-be-optimized-by-gradient-descent-in-large-recurrent-networks-with-hebbian-plastic-connections" class="headerlink" title="we show that plasticity , just like connection weights , can be optimized by gradient descent in large recurrent networks with hebbian plastic connections ."></a>we show that plasticity , just like connection weights , can be optimized by gradient descent in large recurrent networks with hebbian plastic connections .</h3><h3 id="First-recurrent-plastic-networks-with-more-than-two-million-parameters-can-be-trained-to-memorize-and-reconstruct-sets-of-novel-high-dimensional-natural-images-not-seen-during-training"><a href="#First-recurrent-plastic-networks-with-more-than-two-million-parameters-can-be-trained-to-memorize-and-reconstruct-sets-of-novel-high-dimensional-natural-images-not-seen-during-training" class="headerlink" title="First , recurrent plastic networks with more than two million parameters can be trained to memorize and reconstruct sets of novel , high-dimensional natural images not seen during training ."></a>First , recurrent plastic networks with more than two million parameters can be trained to memorize and reconstruct sets of novel , high-dimensional natural images not seen during training .</h3><ul><li>超过两百万参数的递归塑性网络可以被训练来记忆和重建，在训练中没有出现过的创新高维的自然图像数据集。 </li></ul><h3 id="Crucially-traditional-non-plastic-recurrent-networks-fail-to-solve-this-task"><a href="#Crucially-traditional-non-plastic-recurrent-networks-fail-to-solve-this-task" class="headerlink" title="Crucially , traditional non-plastic recurrent networks fail to solve this task ."></a>Crucially , traditional non-plastic recurrent networks fail to solve this task .</h3><ul><li>至关重要的是，传统非塑性循环神经网络无法解决这个问题</li></ul><h3 id="Furthermore-trained-plastic-networks-can-also-solve-generic-meta-learning-tasks-such-as-the-Omniglot-task，with-competitive-results-and-little-parameter-overhead"><a href="#Furthermore-trained-plastic-networks-can-also-solve-generic-meta-learning-tasks-such-as-the-Omniglot-task，with-competitive-results-and-little-parameter-overhead" class="headerlink" title="Furthermore , trained plastic networks can also solve generic meta-learning tasks such as the Omniglot task，with competitive results, and little parameter overhead."></a>Furthermore , trained plastic networks can also solve generic meta-learning tasks such as the Omniglot task，with competitive results, and little parameter overhead.</h3><ul><li>更好的是， 训练塑性神经网络也可以解决像“Omniglot”任务， 有着复杂结果和无限参数的通用元学习任务</li></ul><h3 id="Finally-in-reinforcement-learning-settings-plastic-networks-outperform-a-non-plastic-equivalent-in-a-maze-exploration-task"><a href="#Finally-in-reinforcement-learning-settings-plastic-networks-outperform-a-non-plastic-equivalent-in-a-maze-exploration-task" class="headerlink" title="Finally , in reinforcement learning settings , plastic networks outperform a non-plastic equivalent in a maze exploration task."></a>Finally , in reinforcement learning settings , plastic networks outperform a non-plastic equivalent in a maze exploration task.</h3><ul><li>最后， 在强化学习迷宫问题中，塑性网络比非塑性网络的表现效果更好</li></ul><h3 id="We-conclude-that-differentiable-plasticity-may-provide-a-powerful-novel-approach-to-the-learning-to-learn-problem"><a href="#We-conclude-that-differentiable-plasticity-may-provide-a-powerful-novel-approach-to-the-learning-to-learn-problem" class="headerlink" title="We conclude that differentiable plasticity may provide a powerful novel approach to the learning-to-learn problem ."></a>We conclude that differentiable plasticity may provide a powerful novel approach to the learning-to-learn problem .</h3><ul><li>总结，可微塑性网络也许为“learn to learn ”问题提供了更有力创新的方法。</li></ul><h2 id="Introduction-the-problem-of-“learn-to-learn-“"><a href="#Introduction-the-problem-of-“learn-to-learn-“" class="headerlink" title="Introduction : the problem of “learn to learn “"></a>Introduction : the problem of “learn to learn “</h2><h3 id="Many-of-the-recent-spectacular-successes-in-machine-learning-involve-learning-one-complex-task-very-well-Through-extensive-training-over-thousands-or-millions-of-training-examples"><a href="#Many-of-the-recent-spectacular-successes-in-machine-learning-involve-learning-one-complex-task-very-well-Through-extensive-training-over-thousands-or-millions-of-training-examples" class="headerlink" title="Many of the recent spectacular successes in machine learning involve learning one complex task very well,Through extensive training over thousands or millions of training examples ."></a>Many of the recent spectacular successes in machine learning involve learning one complex task very well,Through extensive training over thousands or millions of training examples .</h3><h3 id="After-learning-is-complete-the-agent’s-knowledge-is-fixed-and-unchanging"><a href="#After-learning-is-complete-the-agent’s-knowledge-is-fixed-and-unchanging" class="headerlink" title="After learning is complete, the agent’s knowledge is fixed and unchanging ;"></a>After learning is complete, the agent’s knowledge is fixed and unchanging ;</h3><ul><li>现在的学习方法中， 智能体的知识在学习完后是固定不变的</li></ul><h3 id="If-the-agent-is-to-be-applie-to-a-different-task-it-must-be-re-trained-again-requiring-a-very-large-number-of-new-training-examples"><a href="#If-the-agent-is-to-be-applie-to-a-different-task-it-must-be-re-trained-again-requiring-a-very-large-number-of-new-training-examples" class="headerlink" title="If the agent is to be applie to a different task , it must be re-trained , again requiring a very large number of new training examples."></a>If the agent is to be applie to a different task , it must be re-trained , again requiring a very large number of new training examples.</h3><ul><li>如果智能体被要求执行一个不同的任务，它必须被重新训练， 在此需要大量的训练数据。</li></ul><h3 id="By-constrast-biological-agents-exhibit-a-remark-able-ability-to-learn-quickly-and-efficiently-from-ongoing-experience"><a href="#By-constrast-biological-agents-exhibit-a-remark-able-ability-to-learn-quickly-and-efficiently-from-ongoing-experience" class="headerlink" title="By constrast, biological agents exhibit a remark-able ability to learn quickly and efficiently from ongoing experience :"></a>By constrast, biological agents exhibit a remark-able ability to learn quickly and efficiently from ongoing experience :</h3><ul><li>animals can learn to navigate and remember the location of food sources, discover and remember rewarding or aversive properties of novel objects and situations,etc.- often from a single exposere . </li></ul><h3 id="An-additional-beenefit-of-autonomous-learning-abilities"><a href="#An-additional-beenefit-of-autonomous-learning-abilities" class="headerlink" title="An additional beenefit of autonomous learning abilities"></a>An additional beenefit of autonomous learning abilities</h3><ul><li>In many tasks (e.g. object recognition , maze navigation ,etc. )</li><li><p>The bulk of fixed , unchanging structure in the task can be stored in the fixed knowledge of the agent,leaving only the changing , contingent parameters of the specific situation to be learned from experience. </p><ul><li>任务中大部分不改变的结构可以被存储智能体固定的知识中，只留下改变的，特殊场景的持续变化的参数，从经验中学习。</li></ul></li></ul><h3 id="As-a-result-learning-the-actual-specific-instance-of-the-task-at-hand-that-is-the-actual-latent-parameters-that-do-vary-across-multiple-instances-of-the-general-task-can-be-extremely-fast-requiring-few-or-even-a-single-experience-with-the-environment"><a href="#As-a-result-learning-the-actual-specific-instance-of-the-task-at-hand-that-is-the-actual-latent-parameters-that-do-vary-across-multiple-instances-of-the-general-task-can-be-extremely-fast-requiring-few-or-even-a-single-experience-with-the-environment" class="headerlink" title="As a result, learning the actual specific instance of the task at hand(that is , the actual latent parameters that do vary across multiple instances of the general task ) can be extremely fast requiring few or even a single experience with the environment."></a>As a result, learning the actual specific instance of the task at hand(that is , the actual latent parameters that do vary across multiple instances of the general task ) can be extremely fast requiring few or even a single experience with the environment.</h3><ul><li>因此， 学习当前任务的特定实例，可能非常快， 甚至只需要当前环境中单独的经验</li></ul><h3 id="Several-meta-learning-methods-have-been-proposed-to-train-agents-to-learn-autonomously"><a href="#Several-meta-learning-methods-have-been-proposed-to-train-agents-to-learn-autonomously" class="headerlink" title="Several meta-learning methods have been proposed to train agents to learn autonomously ."></a>Several meta-learning methods have been proposed to train agents to learn autonomously .</h3><ul><li>几种元学习方法以及被提出来训练智能体自动学习。</li></ul><h3 id="However-unlike-in-current-approaches-in-biological-brains-long-term-learning-is-thought-to-occur-primarily-through-synaptic-plasticity"><a href="#However-unlike-in-current-approaches-in-biological-brains-long-term-learning-is-thought-to-occur-primarily-through-synaptic-plasticity" class="headerlink" title="However , unlike in current approaches , in biological brains long-term learning is thought to occur primarily through synaptic plasticity ."></a>However , unlike in current approaches , in biological brains long-term learning is thought to occur primarily through synaptic plasticity .</h3><ul><li>The strengthening and weakening of connections between neurons as a result of neural activity . </li><li>as carefully tuned by evolution over millions of years to enable efficient learning during the lifetime of each individual. </li><li><p>While multiple forms of synaptic plasticity exist, many of them build upon the general principle known as Hebb’srule</p><ul><li>多数突触可塑性都是建立在Hebb规则上的</li></ul></li></ul><h3 id="Hebb’s-rule"><a href="#Hebb’s-rule" class="headerlink" title="Hebb’s rule"></a>Hebb’s rule</h3><ul><li><p>if a neuron repeatedly takes part in making another neuron fire, the connection between them is strengthened </p><ul><li>(often roughly summarized as “neurons that fire together , wire together”)</li></ul></li></ul><h3 id="Designing-neural-networks-with-plastic-connections-has-long-been-explored-with-evolutionary-algorithms-but-has-been-so-far-relatively-less-studied-in-deep-learning"><a href="#Designing-neural-networks-with-plastic-connections-has-long-been-explored-with-evolutionary-algorithms-but-has-been-so-far-relatively-less-studied-in-deep-learning" class="headerlink" title="Designing neural networks with plastic connections has long been explored with evolutionary algorithms , but has been so far relatively less studied in deep learning ."></a>Designing neural networks with plastic connections has long been explored with evolutionary algorithms , but has been so far relatively less studied in deep learning .</h3><h3 id="However-given-the-spectacular-results-of-gradient-descent-in-designing-traditional-plastic-neural-networks-for-complex-tasks-it-would-be-great-interest-to-expand-backpropagation-training-to-networks-with-plastic-connections-optimizing-through-gradient-descent-not-only-the-base-weights-but-also-the-amount-of-plasticity-in-each-connection"><a href="#However-given-the-spectacular-results-of-gradient-descent-in-designing-traditional-plastic-neural-networks-for-complex-tasks-it-would-be-great-interest-to-expand-backpropagation-training-to-networks-with-plastic-connections-optimizing-through-gradient-descent-not-only-the-base-weights-but-also-the-amount-of-plasticity-in-each-connection" class="headerlink" title="However, given the spectacular results of gradient descent in designing traditional -plastic neural networks for complex tasks, it would be great interest to expand backpropagation training to networks with plastic connections - optimizing through gradient descent not only the base weights , but also the amount of plasticity in each connection ."></a>However, given the spectacular results of gradient descent in designing traditional -plastic neural networks for complex tasks, it would be great interest to expand backpropagation training to networks with plastic connections - optimizing through gradient descent not only the base weights , but also the amount of plasticity in each connection .</h3><ul><li>然而，为一些复杂任务设计传统塑性神经网络时，</li></ul><h3 id="We-previously-demonstrate-the-theoretical-feasibility-and-analytical-derivability-of-this-approach"><a href="#We-previously-demonstrate-the-theoretical-feasibility-and-analytical-derivability-of-this-approach" class="headerlink" title="We previously demonstrate the theoretical feasibility and analytical derivability of this approach ."></a>We previously demonstrate the theoretical feasibility and analytical derivability of this approach .</h3><h3 id="Here-we-show-that-this-approach-can-train-large-networks-for-non-trivial-tasks"><a href="#Here-we-show-that-this-approach-can-train-large-networks-for-non-trivial-tasks" class="headerlink" title="Here we show that this approach can train large networks for non-trivial tasks ."></a>Here we show that this approach can train large networks for non-trivial tasks .</h3><h3 id="To-demonstrate-our-approach-we-apply-it-to-three-different-types-of-tasks-complex-pattern-memorization-including-natural-images"><a href="#To-demonstrate-our-approach-we-apply-it-to-three-different-types-of-tasks-complex-pattern-memorization-including-natural-images" class="headerlink" title="To demonstrate our approach , we apply it to three different types of tasks  : complex pattern memorization (including natural images )."></a>To demonstrate our approach , we apply it to three different types of tasks  : complex pattern memorization (including natural images ).</h3><h3 id="one-shot-classification-on-the-Omniglot-dataset-and-reinforcement-learning-in-a-maze-exploration-problem"><a href="#one-shot-classification-on-the-Omniglot-dataset-and-reinforcement-learning-in-a-maze-exploration-problem" class="headerlink" title="one-shot classification (on the Omniglot dataset), and reinforcement learning (in a maze exploration problem ) ."></a>one-shot classification (on the Omniglot dataset), and reinforcement learning (in a maze exploration problem ) .</h3><h3 id="We-show-that-plastic-networks-provide-competitive-results-on-Omniglot-improve-performance-in-maze-exploration-and-outperform-advanced-non-plastic-recurrent-networks-LSTMs-by-orders-of-magnitude-in-complex-pattern-memorization"><a href="#We-show-that-plastic-networks-provide-competitive-results-on-Omniglot-improve-performance-in-maze-exploration-and-outperform-advanced-non-plastic-recurrent-networks-LSTMs-by-orders-of-magnitude-in-complex-pattern-memorization" class="headerlink" title="We show that plastic networks provide competitive results on Omniglot, improve performance in maze exploration and outperform advanced non-plastic recurrent networks (LSTMs) by orders of magnitude in complex pattern memorization ."></a>We show that plastic networks provide competitive results on Omniglot, improve performance in maze exploration and outperform advanced non-plastic recurrent networks (LSTMs) by orders of magnitude in complex pattern memorization .</h3><h3 id="This-result-is-interesting-not-only-for-opening-up-a-new-avenue-of-investigation-in-gradient-based-neural-network-training-but-also-for-showing-that-meta-properties-of-neural-structures-normally-atrributed-to-evolution-or-a-priori-design-are-in-fact-amenable-to-gradient-descent-hinting-at-a-whole-class-of-heretofore-unimagine-meta-learning-algorithms"><a href="#This-result-is-interesting-not-only-for-opening-up-a-new-avenue-of-investigation-in-gradient-based-neural-network-training-but-also-for-showing-that-meta-properties-of-neural-structures-normally-atrributed-to-evolution-or-a-priori-design-are-in-fact-amenable-to-gradient-descent-hinting-at-a-whole-class-of-heretofore-unimagine-meta-learning-algorithms" class="headerlink" title="This result is interesting not only for opening up a new avenue of investigation in gradient-based neural network training , but also for showing that meta -properties of neural structures normally atrributed to evolution or a priori design are in fact amenable to gradient descent , hinting at a whole class of heretofore unimagine meta-learning algorithms"></a>This result is interesting not only for opening up a new avenue of investigation in gradient-based neural network training , but also for showing that meta -properties of neural structures normally atrributed to evolution or a priori design are in fact amenable to gradient descent , hinting at a whole class of heretofore unimagine meta-learning algorithms</h3><h2 id="Differentiable-plasticity"><a href="#Differentiable-plasticity" class="headerlink" title="Differentiable plasticity"></a>Differentiable plasticity</h2><h3 id="To-train-plastic-networks-with-backpropagation-a-plasticity-rule-must-be-specified"><a href="#To-train-plastic-networks-with-backpropagation-a-plasticity-rule-must-be-specified" class="headerlink" title="To train plastic networks with backpropagation , a plasticity rule must be specified."></a>To train plastic networks with backpropagation , a plasticity rule must be specified.</h3><ul><li><blockquote><p>为了使用反向传播训练塑性网络，必须指定一个塑性规则</p></blockquote></li></ul><h3 id="Here-we-choose-a-flexible-formulation-that-keeps-separate-plastic-and-non-plastic-components-for-each-connection"><a href="#Here-we-choose-a-flexible-formulation-that-keeps-separate-plastic-and-non-plastic-components-for-each-connection" class="headerlink" title="Here we choose a flexible formulation that keeps separate plastic and non-plastic components for each connection"></a>Here we choose a flexible formulation that keeps separate plastic and non-plastic components for each connection</h3><ul><li>在这里， 我们选择一个合适的公式，为每个连接保留塑性和非塑性组件。 </li></ul><h3 id="while-allowing-multiple-Hebbian-rules-to-be-easily-implemented-within-the-framework"><a href="#while-allowing-multiple-Hebbian-rules-to-be-easily-implemented-within-the-framework" class="headerlink" title="while allowing multiple Hebbian rules to be easily implemented within the framework."></a>while allowing multiple Hebbian rules to be easily implemented within the framework.</h3><ul><li>同时允许框架内能够轻松实现多个Hebbian rules </li></ul><h3 id="A-connection-between-any-two-neurons-i-and-j-has-both-a-fixed-component-and-plastic-component"><a href="#A-connection-between-any-two-neurons-i-and-j-has-both-a-fixed-component-and-plastic-component" class="headerlink" title="A connection between any two neurons $i$ and $j$ has both a fixed component and plastic component."></a>A connection between any two neurons $i$ and $j$ has both a fixed component and plastic component.</h3><ul><li>任何两个神经元i和j之间，都有一个固定不变的组件 和一个 塑性组件。 </li></ul><h3 id="The-fixed-part-is-just-a-traditional-connection-weight-w-i-j"><a href="#The-fixed-part-is-just-a-traditional-connection-weight-w-i-j" class="headerlink" title="The fixed part is just a traditional connection weight $w_{i,j}$,"></a>The fixed part is just a traditional connection weight $w_{i,j}$,</h3><ul><li>固定组件就是一个传统的连接权重 $w_{i,j}$, </li></ul><h3 id="The-plastic-part-is-stored-in-a-Hebbian-trace-Hebb-i-j-Which-varies-during-a-lifetime-according-to-ongoing-inputs-and-outputs-note-that-we-use-“lifetime”-and-“episode”-interchangeably"><a href="#The-plastic-part-is-stored-in-a-Hebbian-trace-Hebb-i-j-Which-varies-during-a-lifetime-according-to-ongoing-inputs-and-outputs-note-that-we-use-“lifetime”-and-“episode”-interchangeably" class="headerlink" title="The plastic part is stored in a Hebbian trace $Hebb_{i,j}$, Which varies during a lifetime according to ongoing inputs and outputs (note that we use “lifetime” and “episode” interchangeably.)"></a>The plastic part is stored in a <strong><em>Hebbian trace</em></strong> $Hebb_{i,j}$, Which varies during a lifetime according to ongoing inputs and outputs (note that we use “lifetime” and “episode” interchangeably.)</h3><ul><li>塑性组件被存储在一个 Hebbian  跟踪 $Hebb_{i,j}$里面， 在一个生命周期里面随着输入和输出变化。</li></ul><h3 id="In-the-simplest-case-studied-here-the-Hebbian-trace-is-simply-a-running-average-of-the-product-of-pre-and-post-synaptic-activity"><a href="#In-the-simplest-case-studied-here-the-Hebbian-trace-is-simply-a-running-average-of-the-product-of-pre-and-post-synaptic-activity" class="headerlink" title="In the simplest case studied here, the Hebbian trace is simply a running average of the product of pre- and post-synaptic activity ."></a>In the simplest case studied here, the Hebbian trace is simply a running average of the product of pre- and post-synaptic activity .</h3><h3 id="The-relative-importance-of-plastic-and-fixed-components-in-the-connection-is-structurally-determined-by-the-plasticity-coefficient-aerfa-i-j-Which-multiplies-the-Hebbian-trace-to-form-the-full-plastic-component-of-the-connection"><a href="#The-relative-importance-of-plastic-and-fixed-components-in-the-connection-is-structurally-determined-by-the-plasticity-coefficient-aerfa-i-j-Which-multiplies-the-Hebbian-trace-to-form-the-full-plastic-component-of-the-connection" class="headerlink" title="The relative importance of plastic and fixed components in the connection is structurally determined by the plasticity coefficient $\aerfa_{i,j}$, Which multiplies the Hebbian trace to form the full plastic component of the connection."></a>The relative importance of plastic and fixed components in the connection is structurally determined by the plasticity coefficient $\aerfa_{i,j}$, Which multiplies the Hebbian trace to form the full plastic component of the connection.</h3><ul><li>在连接中，塑性组件和固定组件的相对重要性是通过塑性系数结构化决定的， 塑性系数 是 Hebbian trace 相乘来形成连接的全局塑性组件。 </li></ul><h3 id="Thus-at-any-time-the-total-effective-weight-of-the-connection-between-neurons-i-and-j-is-the-sum-of-the-baseline-fixed-weight-w-i-j-，plus-the-hebbian-trace"><a href="#Thus-at-any-time-the-total-effective-weight-of-the-connection-between-neurons-i-and-j-is-the-sum-of-the-baseline-fixed-weight-w-i-j-，plus-the-hebbian-trace" class="headerlink" title="Thus, at any time , the total , effective weight of the connection between neurons i and j is the sum of the baseline(fixed) weight $w_{i,j}$，plus the hebbian trace"></a>Thus, at any time , the total , effective weight of the connection between neurons i and j is the sum of the baseline(fixed) weight $w_{i,j}$，plus the hebbian trace</h3><ul><li>因此， 在任何时候， 神经元i和j之间的所有有效权重， 是固定的权重$w_{i,j}$， 加上Hebbian trace$Hebb_{i,j}$ 乘以塑性系数。</li></ul><h3 id="The"><a href="#The" class="headerlink" title="The"></a>The</h3><ul><li>神经元j的输出 $x_j(t)$ 如下<br><img src="/2019/03/14/PLASTICITY-NEURAL-NETWORKS/1.png" alt=""></li><li>$\sigmma$ 是一个非线性函数 </li><li>input 代表所有给神经元j提供输入的神经元。 </li><li><p>通过这种方式， 取决于权值$w_{i,j}$ 和$\alpha_{i,j}$， </p><ul><li>如果$\alpha=0$ ,一个连接可以是完全fixed的</li><li>如果$w=0$ , 一个连接可以是没有fixed组件的完全plastic的。</li><li>或者一个连接有固定组件和塑性组件。 </li></ul></li></ul><h3 id="The-Hebbian-trace-Hebb-i-j"><a href="#The-Hebbian-trace-Hebb-i-j" class="headerlink" title="The Hebbian trace $Hebb_{i,j}$"></a>The Hebbian trace $Hebb_{i,j}$</h3><ul><li>在每个生命周期的开始初始化为0 </li><li>参数$w_{i,j}$和$\alpha_{i,j}$ ，在整个生命周期被保存，这个神经网络的结构化参数，通过梯度下降法优化， 在一个生命周期最大化期待的性能</li><li><p>$\elta$ ， 学习率， 也是神经网络的一个优化参数， 在本文中，所有的连接共享相同的$\elta$值。 它是整个网络的学习标量参数。</p><ul><li>elta,作为权重衰减项出现， 保证了Hebbian迹的失控正反馈。</li></ul></li><li><p>然而因为，这个权重衰减， hebb迹在输入缺少的情况下衰减到0</p></li><li>不幸的是， 其他更复杂的Hebb规则可以在刺激缺少的情况下，无限保持权重值的稳定性。</li><li>一个更有名的例子就是Oja’s 规则 ， 因此可以用Oja规则替换上面公式中的第二个公式<br><img src="/2019/03/14/PLASTICITY-NEURAL-NETWORKS/2.png" alt=""></li><li>这种方法可以训练神经网络形成持续任意时间的记忆。 </li><li>为了描述我们研究的灵活性， 我们证明了两个规则， 在下面报告的实验中</li></ul><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h2 id="Experiments-and-Results"><a href="#Experiments-and-Results" class="headerlink" title="Experiments and Results"></a>Experiments and Results</h2><h3 id="这个实验被设计用来证明可微塑性实际上在一个元学习框架内起作用，-并且展示它提供了决定性的优势。"><a href="#这个实验被设计用来证明可微塑性实际上在一个元学习框架内起作用，-并且展示它提供了决定性的优势。" class="headerlink" title="这个实验被设计用来证明可微塑性实际上在一个元学习框架内起作用， 并且展示它提供了决定性的优势。"></a>这个实验被设计用来证明可微塑性实际上在一个元学习框架内起作用， 并且展示它提供了决定性的优势。</h3><h3 id="模式记忆-：-二元模式"><a href="#模式记忆-：-二元模式" class="headerlink" title="模式记忆 ： 二元模式"></a>模式记忆 ： 二元模式</h3><ul><li>为了描述这些不同的塑性方法，我们首先把它应用到任意高维模式的快速记忆集合中去， 并且当这些集合暴露出了局部和降维的版本，就重建这些模式。</li><li>可以执行这个任务的神经网络被称为 内容可寻址记忆， 或者 自动联想神经网络</li><li>这个任务是一个有用的测试， 因为使用Hebbian plastic 连接手动设计的循环神经网络可以成功解决这个二元模式</li><li>因此，如果可微的塑性网络有任何帮助， 它也应该嫩自动解决这个问题，这个问题就是， 自动设计可以执行已经存在的手动设计神经网络可以完成的任务 的神经网络</li><li>图1描绘了这个任务的一个生命周期， 该网络连续显示一组5个二维模式。<br><img src="/2019/03/14/PLASTICITY-NEURAL-NETWORKS/3.png" alt=""></li><li>每个二元模式由1000个元素组成， 每一个不是1就是-1， 分别用红色和蓝色表示。 </li><li><p>每个模式展示了10个周期步骤</p><ul><li>在演示文稿之间有输入为0的三个周期步骤</li><li>所有的模式序列通过3次随机顺序展示。</li><li>然后，通过将所述模式的一半比特设置为零，随机选择其中的一个模式并对其进行降级。</li><li>然后将这种退化的模式作为网络的输入</li></ul></li><li><p>网络的任务是输出重建的正确完整模式，在它的记忆中绘制完成损失的降维模式（底部的浅蓝色和红色）</p></li><li>图1下面的架构是完全循环身价还哦，每一个模式元素都有一个神经元， 加上一个固定的输出神经元（偏差），对于所有的1001个神经元， 输入模式是通过固定每个神经元的只，到模式中对应的元素的值来提供的， 如果这个值不是0 的话； </li><li>对于降维模式中的0值输入，对应的神经元没收到模式输入， 并且从侧面连接中唯一地得到他们的输入。 他们必须重建正确的期待的输出结果。 </li><li>输出直接从活跃神经元中读取。 </li><li>神经网络额性能仅仅在最后一步中被评价</li><li>通过计算累计squared误差， 最终的神经网络输出和正确的模式 </li><li>然后根据反向传播计算了 $w$和$\alpha$ 的梯度误差</li><li>然后这些系数通过一个Adam solver 使用学习率 0.001解决了。 </li><li>在这个实验中， 我们使用了简单衰减的Hebbian 公式来更新hebbian迹</li><li>注意，这个神经网络有两个训练参数 （$w$、$\alpha$），加起来是 1001<em>1001</em>2个训练参数。 </li><li>在大概200个周期的时候，误差率缩减到不再变化</li></ul><p><em>XMind: ZEN - Trial Version</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Plastic-NN&quot;&gt;&lt;a href=&quot;#Plastic-NN&quot; class=&quot;headerlink&quot; title=&quot;Plastic NN&quot;&gt;&lt;/a&gt;Plastic NN&lt;/h1&gt;&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; cla
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Thinking Note during Reading SSL</title>
    <link href="http://yoursite.com/2019/03/14/THINKING-NOTE-DURING-READING-SSL/"/>
    <id>http://yoursite.com/2019/03/14/THINKING-NOTE-DURING-READING-SSL/</id>
    <published>2019-03-14T03:04:06.000Z</published>
    <updated>2019-03-14T12:33:05.861Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SSL-Survey"><a href="#SSL-Survey" class="headerlink" title="SSL Survey"></a>SSL Survey</h1><h2 id="监督学习分类中的限制"><a href="#监督学习分类中的限制" class="headerlink" title="监督学习分类中的限制"></a>监督学习分类中的限制</h2><ul><li>需要足够的标签</li><li>学习到的分类器只能区分， 被训练数据覆盖了的实例</li></ul><h2 id="为了解决上面的问题已经有了的一些方案"><a href="#为了解决上面的问题已经有了的一些方案" class="headerlink" title="为了解决上面的问题已经有了的一些方案"></a>为了解决上面的问题已经有了的一些方案</h2><ul><li><p>open set recognition methods</p><blockquote><p>这种方法的分类器不能决定出，没有见过的实例属于什么类别。 </p></blockquote></li><li><p>这些方法的缺陷</p><blockquote><p>如果测试实例， 是没有标签的，在模型学习中没有见过的类别， 学习到的分类器不能决定这些测试实例的类别标签。 </p></blockquote></li></ul><h2 id="一些流行的应用场景"><a href="#一些流行的应用场景" class="headerlink" title="一些流行的应用场景"></a>一些流行的应用场景</h2><p>（那些需要分类器拥有决定测试实例的类别标签的能力的情况。 ）</p><ul><li>目标类别庞大的情景 </li><li>目标类别稀疏的情景</li><li>目标类别随着时间变化</li><li>在一些特殊性的任务中， 需要花费昂贵代价得到带标签的实例 </li></ul><p>为了解决这个问题， ZSL 被提出了</p><h1 id="ZSL-（zero-shot-learning）"><a href="#ZSL-（zero-shot-learning）" class="headerlink" title="ZSL （zero-shot learning）"></a>ZSL （zero-shot learning）</h1><ul><li>目标： 区分出没有标签的实例。</li><li>应用范围： </li><li>计算机视觉</li><li>自然语言处理</li><li>普适计算</li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><img src="/2019/03/14/THINKING-NOTE-DURING-READING-SSL/1.png" alt="图1"></p><ul><li>它的特征空间由两部分组成： 带标签的训练实例 +  不带标签的测试实例<ul><li>每一个实例通常由一个向量vector代表它。 </li><li>每一个实例假设只属于一个类别。 </li></ul></li></ul><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>$S$  是Seen Classes 可见类别的数据集合。<br>$U$  是Unseen Classes 不可见类别的数据集合。</p><p>上面两个集合不相交。 </p><p>$X$  是D维特征空间。<br>$D^{tr}$  是带标签的可见类别训练集合，它等于特征空间X×可见类别数据集S 的乘积集合。<br>$X^{te}$  是测试集合， 它是特征空间中的元素。 </p><h2 id="特征空间"><a href="#特征空间" class="headerlink" title="特征空间"></a>特征空间</h2><p><img src="/2019/03/14/THINKING-NOTE-DURING-READING-SSL/2.png" alt="图2"></p><ul><li>特征空间分类两部分： 带标签的训练实例  +  不带标签的测试实例<ul><li>带标签的训练实例集，由 $D^{tr}$ 表示， 元素代表已知类</li><li>不带标签的测试实例集，由$X^{te}$ 表示， 元素代表了未知类</li></ul></li></ul><h2 id="ZSL的定义"><a href="#ZSL的定义" class="headerlink" title="ZSL的定义"></a>ZSL的定义</h2><ul><li>Zero-Shot Learning<ul><li>给出已知类$S$ 的带标签训练实例集$D^{tr}$ ,ZSL的目标是学习出一个分类器$f$ D维特征空间到未知类U 的映射，这样就可以用来分类未知分类集合$U$中的测试实例$X^{te}$（可以预测$Y^{te}$）</li><li>ZSL是一种迁移学习</li><li>迁移学习可以分为：同类迁移学习(homogenneous)，和异类迁移学习（heterogeneous）<br><img src="/2019/03/14/THINKING-NOTE-DURING-READING-SSL/3.png" alt="图3"><ul><li>同类迁移学习： 源和目标的特征空间及标签空间是相同的</li><li>异类迁移学习： 源和目标的特征空间和标签空间是不同的</li></ul></li><li>ZSL中，源和目标的特征空间相同，但是标签空间是不相同的，分为S和U，已知类和未知类。<br><img src="/2019/03/14/THINKING-NOTE-DURING-READING-SSL/4.png" alt="图4"></li><li>所以ZSL属于迁移学习中的异类迁移学习，</li><li>ZSL和不同标签空间的异类迁移学习（HTL-DLS）很类似，但是区别在于</li><li>区别在于 ， HTL-DLS 的target label space 有带标签的实例，而ZSL没有。 </li></ul></li></ul><h1 id="辅助信息-Auxiliary-information"><a href="#辅助信息-Auxiliary-information" class="headerlink" title="辅助信息 Auxiliary information"></a>辅助信息 Auxiliary information</h1><p>这些辅助信息应该包含所有的 未知类（Unseen Classes），同时， 辅助信息应该对应特征空间的实例。<br>现有的ZSL方法中包含的辅助信息同上是一些语义信息（Semantic Information）<br>辅助信息构造了一个包含已知类(Seen)和未知类（Unseen）的空间</p><ul><li><p>我们假设$\Gamma$ 是这个语义空间，是M维的。 </p><ul><li>$t_i^s\in \Gamma$ 是已知类$c_i^s$的原型</li><li><p>$t_i^u\in \Gamma$ 是未知类$c_i^u$的原型</p></li><li><p>$T^s$</p></li><li><p>$T^u$</p></li><li><p>$\pi$ 是已知类S和未知类U的并集到语义空间T的映射， 这个函数的输入是一种类别标签， 输出对应的类别原型<br><img src="/2019/03/14/THINKING-NOTE-DURING-READING-SSL/5.png" alt="图5"></p><ul><li>在特征空间之外，构造了一个语义空间，</li><li>语义空间中，包含了 已知类的原型（seen class prototype）和未知类的原型。 </li><li>语义空间中的每种类别有对应的向量表示（vector representation）</li><li>特征空间中的每一个实例由对应的向量表示。</li></ul></li></ul></li></ul><p><img src="/2019/03/14/THINKING-NOTE-DURING-READING-SSL/t1.png" alt="表1">本文使用的数学符号。 </p><h1 id="Learning-Settings"><a href="#Learning-Settings" class="headerlink" title="Learning Settings"></a>Learning Settings</h1><ul><li>三种学习设置：<ul><li>CIII 类别归纳实例归纳设置 （Class-Inductive Instance-Inductive Setting）：<ul><li>只有带标签的实例$D^{tr}$ 和已知类原型$T^s$ 用在模型学习中。 </li></ul></li><li>CTII 类别转换实例归纳设置 （Class-Transductive Instance-Inductive (CTII) Setting）：<ul><li>带标签的训练实例$D^tr$ 、已知类原型$T^s$ 、未知类原型$T^u$ 被用在模型训练中。 </li></ul></li><li>CTIT 类别转换实例转换设置 （Class-Transductive Instance-Transductive (CTIT) Setting）：        <ul><li>带标签的训练实例$D^tr$、已知类原型$T^s$ 、未知类原型$T^u$、不带标签的测试实例$X^{te}$ </li></ul></li></ul></li></ul><h1 id="Domain-shift-域转换现象"><a href="#Domain-shift-域转换现象" class="headerlink" title="Domain shift 域转换现象"></a>Domain shift 域转换现象</h1><pre><code>- 在ZSL学习中，在接受了测试实例之后， 使用训练实例的模型的性能将会下降的现象。 </code></pre><h1 id="本文的贡献"><a href="#本文的贡献" class="headerlink" title="本文的贡献"></a>本文的贡献</h1><ul><li>将ZSL方法分为三类：<ul><li>One-Order transformation</li><li>Two-Order transformation</li><li>high-Order transformation</li></ul></li><li>本文的重点是对现有的ZSL方法给出了评估。 <ul><li>我们整理了ZSL中不同的语义空间和方法<br><img src="/2019/03/14/THINKING-NOTE-DURING-READING-SSL/6.png" alt="图6"><ul><li>语义空间分为， 设计语义空间，和习得语义空间<ul><li>设计语义空间分为， 属性空间、字典空间、关键词空间。 </li><li>习得语义空间分为， 标签嵌入空间、文本嵌入空间、图像代表空间。</li></ul></li><li>零向量学习方法分为： 基于分类器的方法、基于实例的方法。 <ul><li>基于分类器的方法分为： 通信方法、关系方法、组合方法</li><li>基于实例的方法分为： 规划方法、 实例借入方法、重组方法</li></ul></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SSL-Survey&quot;&gt;&lt;a href=&quot;#SSL-Survey&quot; class=&quot;headerlink&quot; title=&quot;SSL Survey&quot;&gt;&lt;/a&gt;SSL Survey&lt;/h1&gt;&lt;h2 id=&quot;监督学习分类中的限制&quot;&gt;&lt;a href=&quot;#监督学习分类中的限制&quot;
      
    
    </summary>
    
    
      <category term="SSL" scheme="http://yoursite.com/tags/SSL/"/>
    
  </entry>
  
  <entry>
    <title>SSL Review -2</title>
    <link href="http://yoursite.com/2019/03/10/SSL-REVIEW-2-%20Overview%20of%20Zero-Shot%20Learning/"/>
    <id>http://yoursite.com/2019/03/10/SSL-REVIEW-2- Overview of Zero-Shot Learning/</id>
    <published>2019-03-10T02:10:25.000Z</published>
    <updated>2019-03-11T02:01:53.712Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overview-of-Zero-Shot-learning"><a href="#Overview-of-Zero-Shot-learning" class="headerlink" title="Overview of Zero-Shot learning"></a>Overview of Zero-Shot learning</h1><ul><li><p>the seen classes</p><ul><li>the classes covered by labeled training instances in the feauture space</li></ul></li><li><p>the unseen classes</p><ul><li>unlabeled testing instances in the feature space which belong to another set of classes</li></ul></li><li><p>the feature space</p><ul><li>a real number space</li><li>each instance is represented as a vector within it</li><li>each instance is usually assumed to belong to one class</li></ul></li><li><p><strong>definition</strong></p><ul><li>the Set of Seen Classes:<pre><code>$$S=\\{c_{i}^{s}\|i=1,……,N_{s}\\}$$</code></pre><ul><li>a seen classes:$c_{i}^{j}$</li></ul></li><li>the Set of Unseen Classes:<pre><code>$$U=\\{c_{i}^{u}\\|i=1,N_{u}\\}$$</code></pre></li><li>an unseen class:$C_{i}^{u}$</li><li>Denote that ：${S}\bigcap{U}=\varnothing$</li><li>The Feature Space:$X$, which is $D-dimensional$: $R^{D}$</li><li><p>The set of labeled training instances belonging to seen classes:</p><p>$$D^{tr}=\{(x_{i}^{tr},y_{i}^{tr})\in X\times S\}$$</p></li><li><p>for each labeled instance $(x_i^{tr},y_i^{tr})$,</p><ul><li>$x_i^{tr}$ ：the instance in the feature space ，</li><li>$y_i^{tr}$： the corresponding class label .</li></ul></li><li>The set of testing instances:<br>  $$X^{te}=\{x_i^{te}\in X\}<em>{i=1}^{N</em>{te}}$$<br>  where each $x_i^{te}$ is a testing instance in the feature space.</li><li>The corresponding class labels for $X^{te}$:<br>  $$Y^{te}=\{y_i^{te}\in U\}<em>{i=1}^{N</em>{te}}$$<br>  which are able to be predicted.<h2 id="Definition-1-1-Zero-Shot-Learning"><a href="#Definition-1-1-Zero-Shot-Learning" class="headerlink" title="Definition 1.1 (Zero-Shot Learning)"></a>Definition 1.1 (Zero-Shot Learning)</h2></li></ul></li><li>Given labeled training instances $D^{tr}$ belonging to the seen classes $S$,zero-shot learning aims to learn a classifier $f^u(\cdot):X\rightarrow U$  that can classify testing instances $X^{te}$(i.e. to predict $Y^{te}$) belonging to the unseen classes $U$.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Overview-of-Zero-Shot-learning&quot;&gt;&lt;a href=&quot;#Overview-of-Zero-Shot-learning&quot; class=&quot;headerlink&quot; title=&quot;Overview of Zero-Shot learning&quot;&gt;
      
    
    </summary>
    
    
      <category term="SSL" scheme="http://yoursite.com/tags/SSL/"/>
    
  </entry>
  
  <entry>
    <title>SSL Review -1</title>
    <link href="http://yoursite.com/2019/03/09/SSL-REVIEW-1/"/>
    <id>http://yoursite.com/2019/03/09/SSL-REVIEW-1/</id>
    <published>2019-03-09T14:14:25.000Z</published>
    <updated>2019-03-09T14:18:03.209Z</updated>
    
    <content type="html"><![CDATA[<h1 id="小样本综述：A-Survey-of-Zero-Shot-Learning-Settings-Methods-and-Applications"><a href="#小样本综述：A-Survey-of-Zero-Shot-Learning-Settings-Methods-and-Applications" class="headerlink" title="小样本综述：A Survey of Zero-Shot Learning: Settings, Methods,and Applications"></a>小样本综述：A Survey of Zero-Shot Learning: Settings, Methods,and Applications</h1><h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><h3 id="Classify-zero-short-learning-according-to-the-data-utilized-in-model-optimization"><a href="#Classify-zero-short-learning-according-to-the-data-utilized-in-model-optimization" class="headerlink" title="Classify zero-short learning according to the data utilized in model optimization"></a>Classify zero-short learning according to the data utilized in model optimization</h3><h3 id="different-semantic-spaces-adopted-in-existing-zero-shot-learning-works"><a href="#different-semantic-spaces-adopted-in-existing-zero-shot-learning-works" class="headerlink" title="different semantic spaces adopted in existing zero-shot learning works"></a>different semantic spaces adopted in existing zero-shot learning works</h3><h3 id="categorize-existing-zero-shot-learning-methods"><a href="#categorize-existing-zero-shot-learning-methods" class="headerlink" title="categorize existing zero-shot learning methods"></a>categorize existing zero-shot learning methods</h3><h3 id="different-applications-of-zero-shot-learning"><a href="#different-applications-of-zero-shot-learning" class="headerlink" title="different applications of zero-shot learning"></a>different applications of zero-shot learning</h3><h3 id="future-research-directions-of-zero-shot-learning"><a href="#future-research-directions-of-zero-shot-learning" class="headerlink" title="future research directions of zero-shot learning"></a>future research directions of zero-shot learning</h3><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Resttrictions-for-Supervised-classification"><a href="#Resttrictions-for-Supervised-classification" class="headerlink" title="Resttrictions for Supervised classification"></a>Resttrictions for Supervised classification</h3><ul><li>1、sufficient labeled training instances are needed for each class </li><li>2、the learned classifier can only classify the instances belonging to classes covered by the training data </li><li>3、 it lacks the ability to deal with previously unseen classes </li><li>in practical applications , there may not be sufficient training instances for each class.<br>there could  also be situations in which the classes not covered by the training instances appear in the testing instances. </li></ul><h3 id="Method-to-deal-with-the-problems"><a href="#Method-to-deal-with-the-problems" class="headerlink" title="Method to deal with the problems"></a>Method to deal with the problems</h3><ul><li><p>few-shot learning methods<br>one-shot learing methods</p><ul><li>in these methods , while learning classifiers for the classes with few instances , knowledge contained in instances of other classes is utilized . </li></ul></li><li><p>open set recognition methods ,</p><ul><li>when learning classifier with the training data , the fact of unseen classes existing is taken in consideration </li><li>the learned classifier can  determine whether a testing instance belong to the unseen classes , but it cannot determine which specific unseen class the instance belongs to.</li></ul></li><li><p>the cumulative learning methods<br>the class-incremental learning methods </p><ul><li>proposed for problems in which labeled instances belonging to some previously unseen classes progressively appear after model learning .</li><li>the learned classifier can be adapted with these newly available labeled instances to be able to classify classes covered by them</li></ul></li><li><p>the open world recognition methods </p><ul><li>follow the process of “unseen classes detection , labeled instances of unseen classes acquisition, and model adaption “</li><li>adapt the classifier to be able to classify previously unseen classes with the acquired labeled instances belonging to them</li></ul></li><li><p>disadvantage of the methods under the above learning paradigms</p><ul><li>if the testing instances belong to unseen classes that have no available labeled instances during the model learning . </li><li>the learned classifier cannot determine the class labels of them. </li><li>However , in many practical applications , we need the classifier to have the ability to determine the class labels for the instances belonging to these classes .</li></ul></li><li><p>Some popular application scenarios </p><ul><li><p>The number of target classes is large.</p><ul><li>example: activity recognition</li></ul></li><li><p>Target classes are rare.</p><ul><li>example: fine-grained object classification , recognize flowers of different breeds. </li></ul></li><li><p>Target classes change over time.</p><ul><li>example: recognizing images of products belonging to a certain style and brand. </li></ul></li><li><p>In some particular tasks which is expensive to obtain labeled instances. </p></li></ul></li><li><p>For a  classifier </p><ul><li>it is important for it to have the ability to determine the class label of instances belonging to these classes . </li><li>to solve this problem ,zero-shot learning is proposed .</li></ul></li><li><p>Zero-shot learning</p><ul><li>aim to classify instances belong to the classes that have no labeled instances. </li></ul></li></ul><h3 id="Overview-of-Zero-Shot-learning"><a href="#Overview-of-Zero-Shot-learning" class="headerlink" title="Overview of Zero-Shot learning"></a>Overview of Zero-Shot learning</h3><p><em>XMind: ZEN - Trial Version</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;小样本综述：A-Survey-of-Zero-Shot-Learning-Settings-Methods-and-Applications&quot;&gt;&lt;a href=&quot;#小样本综述：A-Survey-of-Zero-Shot-Learning-Settings-Meth
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>SLAM - PAPER - 1</title>
    <link href="http://yoursite.com/2019/03/04/SLAM-PAPER-1/"/>
    <id>http://yoursite.com/2019/03/04/SLAM-PAPER-1/</id>
    <published>2019-03-04T07:01:14.000Z</published>
    <updated>2019-03-10T06:47:03.959Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Matching-range-constrained-real-time-loop-closure-detection-with-CNNs-features"><a href="#Matching-range-constrained-real-time-loop-closure-detection-with-CNNs-features" class="headerlink" title="Matching-range-constrained real-time loop closure detection with CNNs features"></a>Matching-range-constrained real-time loop closure detection with CNNs features</h2><p>具有匹配范围约束的带重复特征的实时环路闭包检测</p><ul><li><p>abstract</p><ul><li>loop closure detection 闭环检测LCD</li><li>DCNNs</li><li><p>Some researchers</p><ul><li>pre-trained CNNs model</li><li>generating an image representation</li><li>appropriate for visual LCD in SLAM</li></ul></li><li><p>Differences and Challenges between Simple Computer Vision  &amp; Robotic Application</p><ul><li>adjacent images more resemblance</li><li>real-time performance</li></ul></li><li><p>in this paper</p><ul><li><p>making use of the feature generated by CNNs layers</p><ul><li>to implement LCD in real environment</li></ul></li><li><p>the first problem</p><ul><li>provide a value to limit the matching range of images</li></ul></li><li><p>better results</p></li><li><p>improve the real-time performance</p><ul><li>using an efficient feature compression method</li></ul></li></ul></li></ul></li><li><p>background</p><ul><li><p>SLAM algorithm aims</p><ul><li>map an unknown environment</li><li>while simultaneously localizing the robot</li></ul></li><li><p>LCD</p><ul><li>determine whether a robot is back to previously visited location</li><li>correcting the accumulate error is critical for building a consistent map</li><li>One of the most essential techniques in SLAM</li></ul></li><li><p>develop a LCD algorithm</p><ul><li><p>one class of popular and successful techniques</p><ul><li>based on  Matching the current view of the robot with</li><li>Those Corresponding to previously visited locations in the robot map</li><li><p>OTHER</p><ul><li>image matching problem</li></ul></li><li><p>STEPS</p><ul><li>image description</li><li>similarity measurement</li></ul></li><li><p>The state-of-the-art Algorithms</p><ul><li><p>image description</p><ul><li><p>BoW ： bag-of-words model</p><ul><li><p>clusters the visual feature descriptors in images</p><ul><li><p>visual features (Success)</p><ul><li>SIFT</li><li>Surf</li></ul></li></ul></li><li><p>builds the dictionary</p></li><li>find the corresponding words of image</li></ul></li></ul></li><li><p>similarity measurement</p></li></ul></li></ul></li><li><p>Challenges still remain</p><ul><li>in dynamical and large-scale environment</li><li><p>long period of time</p><ul><li>day</li><li>week</li><li>months</li></ul></li><li><p>dramatic condition change</p></li><li>viewpoint change over time</li><li><p>bad news</p><ul><li>the hand-craft methods can not deal with these situations very well</li></ul></li><li><p>good news</p><ul><li>in recent ML and CV conference</li><li>the features generated by convolutional neural networks outperform well in visual recognition classification and detection applications</li></ul></li></ul></li><li><p>advantage of CNNs</p><ul><li>it has been demonstrated to be versatile and transferable</li><li>even though they were trained on a very specific target task</li><li>they can be successfully used to solving different problems</li><li>and may outperform traditional hand-craft features</li></ul></li></ul></li><li><p>Two Challenges appear while we use these features generated by CNNs in pratical environment</p><ul><li><p>Firstly , the adjacent images in the data-set of LCD might have more resemblance  than the images that really form the loop closure</p><ul><li>#?为什么相邻图像比真实构成闭环检测的图像更相似？</li><li>the algorithm tends to identify the adjacent images  as loop closure</li></ul></li><li><p>Secondly , the feature matching is computationally intensive , because the dimension of features generated by CNNs may be very large .</p></li></ul></li></ul></li></ul><p>LCD have to compare the current image to large amount of pre-captured images</p><pre><code>        - 太大的计算量不利于实时性- in this paper    - two solution        - firstly            - provide matching range of candidate images                - #将匹配到一张图片，变成匹配到相似的图片范围里去        - secondly            - a efficient feature compression method                - #有效在于，通过压缩了CNN层得到的图像特征，这样处理的图像变小，处理速度快一点就能提高实时性， （临界性能减小）            - to reduce dimension of feature generated by CNNs</code></pre><h2 id="ViNS-Mono"><a href="#ViNS-Mono" class="headerlink" title="ViNS-Mono"></a>ViNS-Mono</h2><h2 id="遥感影像道路提取研究"><a href="#遥感影像道路提取研究" class="headerlink" title="遥感影像道路提取研究"></a>遥感影像道路提取研究</h2><h3 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h3><ul><li>首先利用各种特征提取方法提取有用特征</li><li>应用各种方法找出满足道路特征的道路</li><li>最后对道路提取结果进行后期优化处理得到最终道路提取结果</li></ul><h3 id="目前的方法"><a href="#目前的方法" class="headerlink" title="目前的方法"></a>目前的方法</h3><ul><li>特征提取</li><li><p>道路提取</p><ul><li>1、同时包含道路拓扑结构信息和宽度信息的提取</li><li>2、只提取出道路中心线的拓扑结构信息</li></ul></li></ul><h2 id="Long-Range-Traversable-Region-Detection-Based-on-Superpixels"><a href="#Long-Range-Traversable-Region-Detection-Based-on-Superpixels" class="headerlink" title="Long Range Traversable Region Detection Based on Superpixels"></a>Long Range Traversable Region Detection Based on Superpixels</h2><p>Clustering for Mobile Robots<br>可达性</p><h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><ul><li>— Traversable region detection</li><li><p>i传统方法缺点</p><ul><li>only  short range traversable regions can be detected</li><li><p>原因</p><ul><li>the limited image resolution and baseline of stereo vision</li></ul></li></ul></li><li><p>本文方法</p><ul><li>detect long range traversable regions without using any supervised or self-supervised learning process</li><li>Superpixels clustering algorithm</li><li>superpixels are  clustered using an improved spectral clustering algorithm to segment the image</li><li><p>integrating short range traversable region detection : u-v-disparity</p><ul><li>then the traversable region can be extended to long range naturally</li></ul></li></ul></li><li><p>result</p><ul><li>works well in different outdoor environments</li><li>detecting range can be improved greatly</li></ul></li></ul><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><p>可达性</p><ul><li>regions that do not contain geometric obstacles</li></ul></li><li><p>采集信息</p><ul><li>ultrasonicsensor</li><li><p>stereo vision</p><ul><li>measure the ranges to objects</li><li>by calculating disparities between stereo images</li></ul></li><li><p>laser scanners</p></li></ul></li><li><p>key</p><ul><li>After acquiring the disparities ,traversable regions or obstacles can be detected robustly and efficiently<br>(using a series of approaches based on u-v-disparties )</li></ul></li><li><p>V-disparity</p><ul><li><p>Aim</p><ul><li>detect Obstacles</li></ul></li><li><p>(u,v)</p><ul><li>坐标</li></ul></li><li><p>ways</p><ul><li>by accumulating pixels with the same disparity value d in each row , a v-disparity image (d,v) was build</li><li><p>perpendicular obstacles can be mapped to vertical lines</p><ul><li>pixel intensity  represents  the width of obstacles</li></ul></li><li><p>the traversable region modelled as a succession of planes can be projected as slanted line segment</p></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Matching-range-constrained-real-time-loop-closure-detection-with-CNNs-features&quot;&gt;&lt;a href=&quot;#Matching-range-constrained-real-time-loop-
      
    
    </summary>
    
      <category term="SLAM" scheme="http://yoursite.com/categories/SLAM/"/>
    
    
      <category term="SLAM" scheme="http://yoursite.com/tags/SLAM/"/>
    
  </entry>
  
  <entry>
    <title>SLAM - PAPER - 1</title>
    <link href="http://yoursite.com/2019/03/04/SLAM-PAPER/"/>
    <id>http://yoursite.com/2019/03/04/SLAM-PAPER/</id>
    <published>2019-03-04T07:01:14.000Z</published>
    <updated>2019-03-04T07:45:00.863Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Matching-range-constrained-real-time-loop-closure-detection-with-CNNs-features"><a href="#Matching-range-constrained-real-time-loop-closure-detection-with-CNNs-features" class="headerlink" title="Matching-range-constrained real-time loop closure detection with CNNs features"></a>Matching-range-constrained real-time loop closure detection with CNNs features</h2><p>具有匹配范围约束的带重复特征的实时环路闭包检测</p><ul><li><p>abstract</p><ul><li>loop closure detection 闭环检测LCD</li><li>DCNNs</li><li><p>Some researchers</p><ul><li>pre-trained CNNs model</li><li>generating an image representation</li><li>appropriate for visual LCD in SLAM</li></ul></li><li><p>Differences and Challenges between Simple Computer Vision  &amp; Robotic Application</p><ul><li>adjacent images more resemblance</li><li>real-time performance</li></ul></li><li><p>in this paper</p><ul><li><p>making use of the feature generated by CNNs layers</p><ul><li>to implement LCD in real environment</li></ul></li><li><p>the first problem</p><ul><li>provide a value to limit the matching range of images</li></ul></li><li><p>better results</p></li><li><p>improve the real-time performance</p><ul><li>using an efficient feature compression method</li></ul></li></ul></li></ul></li><li><p>background</p><ul><li><p>SLAM algorithm aims</p><ul><li>map an unknown environment</li><li>while simultaneously localizing the robot</li></ul></li><li><p>LCD</p><ul><li>determine whether a robot is back to previously visited location</li><li>correcting the accumulate error is critical for building a consistent map</li><li>One of the most essential techniques in SLAM</li></ul></li><li><p>develop a LCD algorithm</p><ul><li><p>one class of popular and successful techniques</p><ul><li>based on  Matching the current view of the robot with</li><li>Those Corresponding to previously visited locations in the robot map</li><li><p>OTHER</p><ul><li>image matching problem</li></ul></li><li><p>STEPS</p><ul><li>image description</li><li>similarity measurement</li></ul></li><li><p>The state-of-the-art Algorithms</p><ul><li><p>image description</p><ul><li><p>BoW ： bag-of-words model</p><ul><li><p>clusters the visual feature descriptors in images</p><ul><li><p>visual features (Success)</p><ul><li>SIFT</li><li>Surf</li></ul></li></ul></li><li><p>builds the dictionary</p></li><li>find the corresponding words of image</li></ul></li></ul></li><li><p>similarity measurement</p></li></ul></li></ul></li><li><p>Challenges still remain</p><ul><li>in dynamical and large-scale environment</li><li><p>long period of time</p><ul><li>day</li><li>week</li><li>months</li></ul></li><li><p>dramatic condition change</p></li><li>viewpoint change over time</li><li><p>bad news</p><ul><li>the hand-craft methods can not deal with these situations very well</li></ul></li><li><p>good news</p><ul><li>in recent ML and CV conference</li><li>the features generated by convolutional neural networks outperform well in visual recognition classification and detection applications</li></ul></li></ul></li><li><p>advantage of CNNs</p><ul><li>it has been demonstrated to be versatile and transferable</li><li>even though they were trained on a very specific target task</li><li>they can be successfully used to solving different problems</li><li>and may outperform traditional hand-craft features</li></ul></li></ul></li><li><p>Two Challenges appear while we use these features generated by CNNs in pratical environment</p><ul><li><p>Firstly , the adjacent images in the data-set of LCD might have more resemblance  than the images that really form the loop closure</p><ul><li>#?为什么相邻图像比真实构成闭环检测的图像更相似？</li><li>the algorithm tends to identify the adjacent images  as loop closure</li></ul></li><li><p>Secondly , the feature matching is computationally intensive , because the dimension of features generated by CNNs may be very large .</p></li></ul></li></ul></li></ul><p>LCD have to compare the current image to large amount of pre-captured images</p><pre><code>        - 太大的计算量不利于实时性- in this paper    - two solution        - firstly            - provide matching range of candidate images                - #将匹配到一张图片，变成匹配到相似的图片范围里去        - secondly            - a efficient feature compression method                - #有效在于，通过压缩了CNN层得到的图像特征，这样处理的图像变小，处理速度快一点就能提高实时性， （临界性能减小）            - to reduce dimension of feature generated by CNNs</code></pre><h2 id="ViNS-Mono"><a href="#ViNS-Mono" class="headerlink" title="ViNS-Mono"></a>ViNS-Mono</h2><h2 id="遥感影像道路提取研究"><a href="#遥感影像道路提取研究" class="headerlink" title="遥感影像道路提取研究"></a>遥感影像道路提取研究</h2><h3 id="基本思路"><a href="#基本思路" class="headerlink" title="基本思路"></a>基本思路</h3><ul><li>首先利用各种特征提取方法提取有用特征</li><li>应用各种方法找出满足道路特征的道路</li><li>最后对道路提取结果进行后期优化处理得到最终道路提取结果</li></ul><h3 id="目前的方法"><a href="#目前的方法" class="headerlink" title="目前的方法"></a>目前的方法</h3><ul><li>特征提取</li><li><p>道路提取</p><ul><li>1、同时包含道路拓扑结构信息和宽度信息的提取</li><li>2、只提取出道路中心线的拓扑结构信息</li></ul></li></ul><h2 id="Long-Range-Traversable-Region-Detection-Based-on-Superpixels"><a href="#Long-Range-Traversable-Region-Detection-Based-on-Superpixels" class="headerlink" title="Long Range Traversable Region Detection Based on Superpixels"></a>Long Range Traversable Region Detection Based on Superpixels</h2><p>Clustering for Mobile Robots<br>可达性</p><h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><ul><li>— Traversable region detection</li><li><p>i传统方法缺点</p><ul><li>only  short range traversable regions can be detected</li><li><p>原因</p><ul><li>the limited image resolution and baseline of stereo vision</li></ul></li></ul></li><li><p>本文方法</p><ul><li>detect long range traversable regions without using any supervised or self-supervised learning process</li><li>Superpixels clustering algorithm</li><li>superpixels are  clustered using an improved spectral clustering algorithm to segment the image</li><li><p>integrating short range traversable region detection : u-v-disparity</p><ul><li>then the traversable region can be extended to long range naturally</li></ul></li></ul></li><li><p>result</p><ul><li>works well in different outdoor environments</li><li>detecting range can be improved greatly</li></ul></li></ul><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><p>可达性</p><ul><li>regions that do not contain geometric obstacles</li></ul></li><li><p>采集信息</p><ul><li>ultrasonicsensor</li><li><p>stereo vision</p><ul><li>measure the ranges to objects</li><li>by calculating disparities between stereo images</li></ul></li><li><p>laser scanners</p></li></ul></li><li><p>key</p><ul><li>After acquiring the disparities ,traversable regions or obstacles can be detected robustly and efficiently<br>(using a series of approaches based on u-v-disparties )</li></ul></li><li><p>V-disparity</p><ul><li><p>Aim</p><ul><li>detect Obstacles</li></ul></li><li><p>(u,v)</p><ul><li>坐标</li></ul></li><li><p>ways</p><ul><li>by accumulating pixels with the same disparity value d in each row , a v-disparity image (d,v) was build</li><li><p>perpendicular obstacles can be mapped to vertical lines</p><ul><li>pixel intensity  represents  the width of obstacles</li></ul></li><li><p>the traversable region modelled as a succession of planes can be projected as slanted line segment</p></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Matching-range-constrained-real-time-loop-closure-detection-with-CNNs-features&quot;&gt;&lt;a href=&quot;#Matching-range-constrained-real-time-loop-
      
    
    </summary>
    
      <category term="SLAM" scheme="http://yoursite.com/categories/SLAM/"/>
    
    
      <category term="SLAM" scheme="http://yoursite.com/tags/SLAM/"/>
    
  </entry>
  
  <entry>
    <title>さようならノート</title>
    <link href="http://yoursite.com/2019/02/17/%E6%96%AD%E7%AB%A0/"/>
    <id>http://yoursite.com/2019/02/17/断章/</id>
    <published>2019-02-17T15:39:00.000Z</published>
    <updated>2019-03-10T06:47:03.911Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/2019/02/17/断章/1.jpg" alt="Cry"></p><p>中断することが喜んでください。<br>中断された心の思い出をマッチング<br>が、絶望的<br>準備と方法<br>単語を置く必要がありますを聞く時<br>あなたを理解すると思う、<br>それは、知っていない彼は個人の心で持っていたことが判明<br>彼は、奇妙に精通しています。<br>酸性または苦いも前例のないです。<br>内臓に影響を及ぼす<br>心臓に血液を返す<br>突然の中心すべて重いです。<br>したいです<br>氷のメモリ<br>破壊されて<br>風の分散<br>灰に残っています。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/2019/02/17/断章/1.jpg&quot; alt=&quot;Cry&quot;&gt;&lt;/p&gt;
&lt;p&gt;中断することが喜んでください。&lt;br&gt;中断された心の思い出をマッチング&lt;br&gt;が、絶望的&lt;br&gt;準備と方法&lt;br&gt;単語を置く必要がありますを聞く時&lt;br&gt;あなたを理解すると思
      
    
    </summary>
    
      <category term="Feeling Notes" scheme="http://yoursite.com/categories/FEELING-NOTES/"/>
    
    
      <category term="Informal essay" scheme="http://yoursite.com/tags/INFORMAL-ESSAY/"/>
    
  </entry>
  
  <entry>
    <title>Five paper about SSL</title>
    <link href="http://yoursite.com/2019/02/17/SSL/"/>
    <id>http://yoursite.com/2019/02/17/SSL/</id>
    <published>2019-02-17T11:00:41.000Z</published>
    <updated>2019-02-17T16:47:20.219Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Zero-Shot-Action-Recognition-with-Error-Correcting-Output-Codes"><a href="#Zero-Shot-Action-Recognition-with-Error-Correcting-Output-Codes" class="headerlink" title="Zero-Shot Action Recognition with Error-Correcting Output Codes"></a>Zero-Shot Action Recognition with Error-Correcting Output Codes</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li><p>主旨</p><ul><li>本文从采用零样本纠错输出码（ZSECOC）的角度来探索ZSAR(Zero-shot action recognition零样本动作识别)</li><li>文中的提出的零样本纠错输出码（ZSECOC）与传统纠错输出码（ECOC）不同之处在于， 为传统ECOC提供了ZSAR的能力。 </li></ul></li><li><p>方法</p><ul><li>从类级语义和内在数据结构中学习出区分可见类别的ZSECOC 。</li><li>通过将可见类别之间已确定的相关性转移到不可见类别之间来隐式地处理域转移</li><li>开发了一种简单的语义转移策略，用于显式地转换已学习的可见类别嵌入，以更好地适应不可见类别的底层结构。</li></ul></li><li><p>优点</p><ul><li>ZSECOC既继承了ECOC的优良特性，又克服了域偏移的问题，使其对ZSAR具有更好的识别能力。</li></ul></li><li><p>评测</p><ul><li>系统地评估了ZSECOC的三个现实行动基准，即奥林匹克运动、HMDB51和UCF101</li><li>实验结果清楚地表明了ZSECOC方法优于目前最先进的方法。</li></ul></li></ul><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><p>情景</p><ul><li>健壮的动作识别通常依赖于大量标记的训练示例。然而，在许多实际的场景中，为不断增长的新类别添加足够的示例是非常不适用的</li></ul></li><li><p>目的</p><ul><li>开发一个能够自动识别来自新/不可见类别的操作的动作识别系统。</li></ul></li><li><p>调研方法</p><ul><li><p>零距离学习（Zero-shot learning ,ZSL）</p><ul><li>可以通过标签嵌入(或称为中间表示)来实现，其中语义属性得到了广泛的应用。</li><li>然而，属性通常是手工指定的，而且非常主观，因为它们要么是启发式定义的，要么是由领域专家提供的。特别是对于零样本动作识别(zero-shot action recognition, ZSAR)，基于属性的识别方法存在一些具体的缺陷。</li><li><p>缺陷</p><ul><li>首先，动作通常由“动词”定义，它们缺乏定义良好的类层次关系。其次，动态操作比对象更复杂，因此很难为不同的操作指定合适的属性池。</li></ul></li></ul></li><li><p>字嵌入（ word embeddings）</p><ul><li>通过使用来自大型文本语料库(例如wikipedia)的单词向量，我们只需要类别名称来构建标签嵌入，而不需要耗时的手动指定属性。</li><li><p>缺陷</p><ul><li>然而，嵌入空间的维数m通常较高(通常为m &gt;1000)，因此对于需要训练m个可视化语义映射函数(即从视觉特征到标签嵌入的投影)。</li><li>此外，词向量只考虑类别名称的文本分布式表示，没有考虑原始的可视化数据结构。这将直接导致最终ZSAR的识别能力较差。</li></ul></li></ul></li><li><p>期望的方法ECOC</p><ul><li>因此，我们非常希望寻找一种有区别的、可伸缩的、可以绕过上述缺陷的标签嵌入。通过仔细研究ZSAR的本质，我们发现我们的目标直观上等同于设计分类级纠错输出代码(ECOC)。</li><li><p>优点</p><ul><li><p>Error-correcting abilities.</p><ul><li>通过使用一些冗余位，我们可以容忍一定程度的错误1。利用这一特性可以增强ZSAR的鲁棒性。</li></ul></li><li><p>High efficiency.</p><ul><li>只需少量位元，二进制码匹配速度极快，可实现大规模的ZSAR。</li></ul></li><li><p>Accurate binary classification for each bit.</p><ul><li>这可能导致可靠的可视化语义映射。</li></ul></li></ul></li><li><p>缺陷</p><ul><li>然而，以往的ECOC研究大多针对多类分类，对ZSL的研究较少。这可能是因为直接使用训练在可见类别上的分类器来预测不可见实例将导致较差的性能(称为域移位[23])</li></ul></li></ul></li></ul></li><li><p>本文方法</p><ul><li>具体地说，我们从从大规模文本语料库中获取的分类级语义关联中推导出判别ZSECOC，即谷歌新闻(≈1000亿字)。</li><li>类别之间的语义关联就像一条隧道，将重要的知识从可见的类别隐式地转移到不可见的类别，例如，未知的“三级跳”可以从“跳高”和“跳远”中学习。</li><li>这种知识转移可以在一定程度上解决领域转移问题。在设计判别ZSECOC时，除了保留语义外，还考虑了视觉数据固有的局部结构。</li><li>此外，与需要从不可见类别中访问可视数据的转导方法[23,59,60]不同，我们开发了一种不使用任何不可见数据的简单语义转移策略，为不可见类别生成有效的ZSECOC。</li><li>这种策略显式地转换了可见类别的学习嵌入，以更好地适应不可见类别的底层语义结构。这样可以进一步消除域偏移的影响。</li></ul></li><li><p>本文主要贡献</p><ul><li><p>1</p><ul><li>通过设计有区别的ZSECOC来解决ZSAR问题。我们利用定义良好的类层次关系的词向量，通过发现所见类别之间的语义相关性，定量地度量它们，从而使传统的ECOC具备了ZSAR的能力。</li><li>已建立的语义知识进一步转移到语义相关的无形范畴。因此，提出的ZSECOC既继承了ECOC的固有优势，又克服了域偏移的问题。</li></ul></li><li><p>2</p><ul><li>除了保留类别级语义外，我们的ZSECOC还包含实例级可视数据结构。针对这一问题，提出了一种联合优化框架。高质量的ZSECOC是通过高效的离散优化直接学习的，没有任何松弛。</li></ul></li><li><p>3</p><ul><li>针对奥运会运动项目[39]、HMDB51[24]和UCF101[53]这三个真实的视频动作数据集，对提出的ZSECOC进行了系统的评价。</li><li>就ZSAR而言，最先进的性能清楚地展示了我们方法的优越性。</li></ul></li></ul></li></ul><h2 id="Zero-shot-Learning-Using-Synthesised-Unseen-Visual-Data-with-Diffusion-Regularisation"><a href="#Zero-shot-Learning-Using-Synthesised-Unseen-Visual-Data-with-Diffusion-Regularisation" class="headerlink" title="Zero-shot Learning Using Synthesised Unseen Visual Data with Diffusion Regularisation"></a>Zero-shot Learning Using Synthesised Unseen Visual Data with Diffusion Regularisation</h2><h3 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li><p>背景</p><ul><li>零距离学习(Zero-shot Learning, ZSL)利用视觉属性或自然语言语义作为中间层线索，将低层特征与高层类关联起来，这是该思想的一个新颖扩展</li></ul></li><li><p>目标</p><ul><li>我们的目标是仅使用语义属性来合成新类的训练数据。</li></ul></li><li><p>挑战</p><ul><li>首先，如何防止合成数据过度拟合到训练组?</li><li>其次，如何保证合成的数据对ZSL任务具有鉴别性?</li><li>第三，我们观察到只有少数维度的学习特征获得高的方差，而其余的大部分维度没有提供信息。</li></ul></li><li><p>如何解决</p><ul><li>问题是如何使集中的信息扩散到合成数据的大部分维度。</li><li>提出了一种新的嵌入算法，即不可见视觉数据合成(UVDS)算法，该算法将语义特征投射到高维视觉特征空间中。</li><li><p>在我们提出的算法中引入了两种主要的技术。</p><ul><li>我们引入了一个潜在的嵌入空间，旨在调和视觉空间和语义空间的结构差异，同时保留局部结构。</li><li>我们提出了一种新的扩散正则化(DR)，它明确地迫使方差扩散到合成数据的大多数维度上。通过正交旋转(更准确的说是正交变换)，DR可以去除冗余的相关属性，进一步缓解过拟合问题。</li></ul></li><li><p>效果</p><ul><li>在四个基准数据集上，我们展示了使用合成的不可见数据进行零距离学习的好处。大量的实验结果表明，我们提出的方法明显优于最先进的方法。</li></ul></li></ul></li></ul><h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><p>ZSL</p><ul><li>利用一组封闭的语义模型，这些模型可以泛化成越来越多的新类[1]、[2]、[3]、[4]。因为语义信息可以通过人类知识获得，所以可以动态地创建新类，而不需要收集任何新的可视化数据。</li><li>共同范式的灵感来自于人类仅仅通过了解概念描述就可以识别新事物，因为我们可以将概念与我们之前的知识联系起来。</li><li><p>遵循这种思想，ZSL的第一步是训练一个可以将可视化数据映射到语义表示的预测模型。</p><ul><li>前者开发了旨在从视觉数据准确预测人类知识的高级模型，如概率模型DAP和IAP</li></ul></li><li><p>此后，只要知道新类别的语义描述，就可以识别它们。现有的ZSL研究分为两大主流:预测模型和语义表示设计。</p></li></ul></li><li><p>研究近况</p><ul><li>最近的研究利用嵌入方法作为低层特征和类标签之间的中间层。</li><li>此外，一些新颖的著作研究了如何直接构造不可见类的分类器。</li><li>后一种流侧重于如何有效地表示可以归纳为新类的人类知识，如人类可命名属性、词向量、文本描述以及类相似性。</li></ul></li><li><p>方法不足</p><ul><li>上述方法存在一个共同的不足，即在语义信息不断增加、新类不断添加的情况下，训练的可视化示例无法扩展。由于新概念不断增长，这是不可避免的</li></ul></li><li><p>本文的方法</p><ul><li>在这篇论文中，我们提议对不可见类的训练数据进行合成。我们的想法是受到人类想象力的启发。</li><li>给出一个语义描述，人类可以将熟悉的视觉元素联系起来，然后想象一个近似的场景。</li><li>值得注意的是，我们的方法不同于[1]中的图像合成，因为从语义上合成的图像很难覆盖视觉表象的巨大变化。取而代之的是，我们合成有区别的低级特征来训练ZSL的监督分类器。</li><li>这种方法在ZSL任务和传统的监督分类器之间提供了一个直接的接口。</li><li>此外，它还支持高级概念和低级可视特性之间的信息交互流。这样，训练集可以扩展到与语义表示一样大</li></ul></li><li><p>面临的技术难题</p><ul><li><p>首先是视觉语义的差异。</p><ul><li>由于提取的数据源和方法的视觉特征和语义特征不同，这两个数据空间的数据分布可能存在显著差异。一个空间中的两个闭合点在另一个空间中可能很远。例如，[23]报道，同样的属性“HasTail”可能在“Zebra”和“Pig”的视觉外观上有很大的区别。然而，我们希望该模型能够有效捕获语义-视觉关联，而不是针对[23]中识别任务的“域转移问题”</li></ul></li><li><p>第二个问题是方差衰减。</p><ul><li>由于视觉特征维数通常远大于语义表征维数，学习投影容易出现不平衡，即投影维数的方差变化严重。如图6所示，与真实数据相比，我们观察到线性投影合成的数据存在显著的方差衰减。大多数投影维数的方差都非常小，说明它们获得的信息很少。由于大量的冗余维度，这种预测会导致性能下降。因此，挑战在于如何使信息以平衡的投影扩散到合成数据的大部分维度。据我们所知，这个问题在之前的ZSL文献中没有被发现</li></ul></li></ul></li><li><p>提出的方法</p><ul><li>提出了一种新的嵌入算法，即不可见视觉数据合成(UVDS)算法，该算法将语义特征投射到高维视觉特征空间中。</li><li>对于第一个问题，我们引入了一个潜在的嵌入空间来调和视觉空间和语义空间之间的结构差异。我们使用双图(GR)来保持视觉和语义空间的局部结构。</li><li>对于第二个问题，我们提出了一个新的扩散正则化(DR)，它明确地使信息扩散到合成数据的所有维度。具体地说，我们使用方差作为测量来强制信息在合成数据的维度上扩散。</li><li>我们证明了这种格式等价于找到正交旋转变换。同时，我们还发现了一种优雅的正交旋转形式，它使用了有效解的2,1范数正则化。</li><li>除了上述两个问题，合成的数据对ZSL任务也应该是有区别的。直接回归模型倾向于学习两个空间之间的主成分，这导致了对训练集分类的高度偏差。我们认为这是一个过拟合的问题，即训练后的模型在可见类的合成数据上可以获得较高的性能，但在合成的不可见数据上性能会显著下降。</li><li>我们的经验表明，上述GR和DR可以互补地缓解过拟合问题:DR不损害局部结构的保留，而是通过正交旋转消除语义空间中的冗余相关性，从而有利于数据的合成。</li></ul></li><li><p>贡献</p><ul><li>一个直观的框架，使我们能够从给定的语义属性合成不可见的数据。</li><li>合成的数据可以直接提供给典型的分类器，并导致在四个基准数据集的最先进的性能。</li><li>一种新的扩散正则化，可以显式地使信息扩散到合成数据的各个维度。我们通过优化正交旋转问题来实现信息扩散。我们提供了一种有效的优化策略来解决这一问题，同时数据结构的保存和数据重建</li></ul></li></ul><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="http://blog.sciencenet.cn/blog-205121-1114916.html" target="_blank" rel="noopener">http://blog.sciencenet.cn/blog-205121-1114916.html</a></li></ul><h2 id="Prototypical-Networks-for-Few-shot-Learning"><a href="#Prototypical-Networks-for-Few-shot-Learning" class="headerlink" title="Prototypical Networks for Few-shot Learning"></a>Prototypical Networks for Few-shot Learning</h2><h3 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li><p>目的</p><ul><li>针对小波分类问题，我们提出了原型网络，其中分类器必须推广到训练集中没有出现的新类，只给出每个新类的少量示例。</li><li>原型网络学习一个度量空间，在这个空间中，可以通过计算到每个类的原型表示的距离来执行分类。与近年来的少镜头学习方法相比，它们反映了一种更简单的归纳偏差，在这种有限的数据体制下是有益的，并取得了良好的效果。</li></ul></li><li><p>结果</p><ul><li>我们提供的分析表明，一些简单的设计决策相对于最近涉及复杂架构选择和元学习的方法可以产生实质性的改进。我们进一步将原型网络扩展到零距离学习，并在CU-Birds数据集上实现了最先进的结果</li></ul></li></ul><h3 id="Introduction-2"><a href="#Introduction-2" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><p>小样本分类</p><ul><li>few -shot classification[22,18,15]是一项任务，其中分类器必须进行调整，以适应在培训中没有看到的新类，只给出每个类的几个示例。一个简单的方法，例如在新数据上重新训练模型，将会严重地过度拟合。虽然这个问题相当困难，但已经证明人类有能力执行哪怕是一次分类，即只给出每个新类的一个示例，并且具有很高的准确率[18]。</li></ul></li><li><p>近期两种方法</p><ul><li><p>1</p><ul><li>Vinyals et al.[32]提出了匹配网络，该网络使用一种注意力机制来预测未标记点(查询集)的类。<br>匹配网络可以解释为在嵌入空间中应用的加权最近邻分类器。</li><li>值得注意的是，该模型利用了训练过程中被称为插曲的抽样小批量，其中每一集都被设计成通过子抽样类和数据点来模拟少数镜头任务。章节的使用使得训练问题更加忠实于测试环境，从而提高了泛化能力。</li></ul></li><li><p>2</p><ul><li>Ravi和Larochelle[24]进一步提出了情景式训练的概念，并提出了一种元学习的方法来实现少镜头学习。他们的方法包括培训</li><li>LSTM[11]生成对分类器的更新，给定一个集，这样就可以很好地推广到一个测试集。</li><li>在这里，LSTM元学习者不是在多个情景中训练单个模型，而是学习为每个情景训练一个定制的模型。</li></ul></li></ul></li><li><p>本文的方法的思想</p><ul><li>我们通过解决过拟合的关键问题来解决小批量学习的问题。由于数据非常有限，我们假设分类器应该有一个非常简单的归纳偏差。我们的方法，原型网络，是基于这样一种思想，即存在一种嵌入，其中点围绕每个类的单一原型表示聚类。为了做到这一点，我们使用神经网络学习了输入到嵌入空间的非线性映射，并将类的原型作为其在嵌入空间中支持集的平均值。</li><li>我们采用同样的方法来处理零距离学习;在这里，每个类都带有元数据，提供了类的高级描述，而不是少量标记的示例。因此，我们学习将元数据嵌入到共享空间中，作为每个类的原型。</li><li>就像在少数情况下那样，通过为嵌入式查询点查找最近的类原型来执行分类</li></ul></li><li><p>本文方法</p><ul><li>在这篇论文中，我们建立了原型网络的两种设置，少拍和零拍。</li><li>我们在一次设置中绘制匹配网络的连接，并分析模型中使用的底层距离函数。特别地，我们将原型网络与聚类[4]联系起来，以证明在使用Bregman散度计算距离(如平方欧氏距离)时使用类均值作为原型是合理的。</li><li>我们从经验上发现，距离的选择是至关重要的，因为欧几里得距离远远优于更常用的余弦相似度。在几个基准任务上，我们实现了最先进的性能。</li><li>与最近的元学习算法相比，原型网络更简单、更有效，这使得它们成为一种吸引人的少目标和零目标学习方法</li></ul></li></ul><h3 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://blog.csdn.net/u014767662/article/details/81670215" target="_blank" rel="noopener">https://blog.csdn.net/u014767662/article/details/81670215</a></li></ul><h2 id="A-multimodal-cortical-network-for"><a href="#A-multimodal-cortical-network-for" class="headerlink" title="A multimodal cortical network for"></a>A multimodal cortical network for</h2><p>the detection of changes in the<br>sensory environment</p><h3 id="Abstract-3"><a href="#Abstract-3" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li><p>引入</p><ul><li>经历突然变化的感官刺激会吸引注意力，并优先进入我们的意识。</li><li>我们使用事件相关的功能性磁共振成像(fMRI)来识别大脑中对视觉、听觉和触觉刺激变化做出反应的区域。单模反应区包括视觉、听觉和躯体感觉联合皮层。</li><li>多模态反应区包括颞顶叶交界处、额下回、岛叶、左扣带回和辅助运动区等右脑网络。这些结果揭示了一个分布式的多模态网络，用于无意识地注意感官环境中的事件。</li><li>该网络包含被认为是P300事件相关电位基础的区域，与半eglect综合征患者受损的皮层区域密切相关。</li></ul></li></ul><h3 id="Introduction-3"><a href="#Introduction-3" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><p>引入</p><ul><li>感知环境变化的能力对生存至关重要。有必要关注这些变化，以评估和修改在面临发展障碍、机会或威胁时的行为。因此，感官环境的变化，尤其是突然的变化，往往会不由自主地引起注意。经历变化的感官元素也优先地将自身插入意识中。例如，一个徒步旅行者可能不会注意到持续不断的鸟鸣声，除非他们突然停止，这时，徒步旅行者会意识到这两种声音</li><li>当处理感官世界刺激的能力丧失时，就像患有忽视综合症的患者一样，对刺激的意识也丧失了1,2。理解大脑探测感觉环境变化的机制，将有助于我们更好地理解无意识注意和意识的机制。</li><li>我们使用事件相关功能核磁共振成像来识别神经解剖结构的网络，这一网络是检测感觉环境变化的基础。视觉、听觉和触觉刺激被用来识别对多种感觉模式变化作出反应的区域。这些多模态区域特别有助于理解高阶认知过程，如构建一个完整的、多感官感知环境、将注意力引向该环境的显著特征以及选择这些特征以进入意识</li></ul></li><li><p>实验</p><ul><li>受试者在接受视觉、听觉和触觉刺激的同时接受fMRI检查。为避免因反应选择、计划或工作记忆而激活，实验过程中不要求受试者做出任何形式的反应。相反，他们只是被动地观察刺激。</li><li>关于刺激事件检测的研究经常涉及到</li><li>“古怪”的实验方案，在这个方案中，研究对象面对一系列重复的、标准的刺激物，这些刺激物偶尔会被不同的刺激物打断</li><li>“古怪”的刺激。我们的研究使用了这种方法的修正版本。在我们的方案中，每一种刺激方式都是连续呈现的，但在两种不同的状态(A和b)之间是独立交替的</li><li>A到B或B到A(图1)</li><li>我们使用这些抵消刺激状态之间的转换,而不是一个典型的古怪的刺激,以确保激活是由于一般质量的刺激和变化并不仅仅是由于不同的一些具体特征古怪的刺激与标准相比。每14秒就有3种感官模式中的一种发生转换，以随机顺序排列，以最小化预期和习惯的影响。</li><li>为了识别激活，我们将转换视为刺激事件。这种方法使我们能够识别在单一感觉模式下对转换有反应的皮层区域，以及在多种感觉模式下对转换有反应的皮层网络</li></ul></li></ul><h2 id="Are-GANs-Created-Equal-A-Large-Scale-Study"><a href="#Are-GANs-Created-Equal-A-Large-Scale-Study" class="headerlink" title="Are GANs Created Equal? A Large-Scale Study"></a>Are GANs Created Equal? A Large-Scale Study</h2><h3 id="Abstract-4"><a href="#Abstract-4" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li><p>生成对抗网络</p><ul><li>生成对抗网络(GAN)是生成模型的一个强大子类。尽管有非常丰富的研究活动导致许多有趣的</li><li>GAN算法，仍然很难评估哪种算法比其他算法表现得更好。我们对先进的模型和评价措施进行了中立的、多方面的大规模实证研究。</li></ul></li><li><p>分析</p><ul><li>我们发现，大多数模型都可以达到类似的分数，只要有足够的超参数优化和随机重启。</li><li>这表明改进可以来自更高的计算预算和比基本算法更改更多的调优。</li></ul></li><li><p>困难</p><ul><li>为了克服当前度量标准的一些局限性，我们还提出了几个可以计算精确度和召回率的数据集。我们的实验结果表明，今后的GAN研究应该建立在更加系统和客观的评价程序的基础上。</li></ul></li><li><p>方法</p><ul><li>最后，我们没有发现任何经过测试的算法始终优于[9]中引入的非饱和GAN的证据。</li></ul></li></ul><h3 id="Introduction-4"><a href="#Introduction-4" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><p>本文贡献</p><ul><li><p>1</p><ul><li>我们提供了一个公平和全面的最先进的比较</li><li>GANs和经验表明，如果有足够高的计算预算，它们几乎都可以达到FID的类似值</li></ul></li><li><p>2</p><ul><li>We provide strong empirical evidence2 that to compare GANs</li><li>it is necessary to report a summary of distribution of results, rather than the best result achieved, due</li><li>to the randomness of the optimization process and model instability. (</li></ul></li><li><p>3</p><ul><li>我们评估FID对模式下降的鲁棒性，使用不同的编码网络，并提供最佳的估计</li><li>FID可以在经典数据集上实现。</li></ul></li><li><p>4</p><ul><li>我们介绍了一系列难度越来越大的任务，可以对这些任务进行近似计算，如精度和召回等。</li></ul></li><li><p>5</p><ul><li>开源实现</li></ul></li></ul></li></ul><h3 id="参考资料-2"><a href="#参考资料-2" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="http://www.sohu.com/a/207548482_465975" target="_blank" rel="noopener">http://www.sohu.com/a/207548482_465975</a></li></ul><h2 id="Few-shot-learning-of-neural-networks-from"><a href="#Few-shot-learning-of-neural-networks-from" class="headerlink" title="Few-shot learning of neural networks from"></a>Few-shot learning of neural networks from</h2><p>scratch by pseudo example optimization</p><h3 id="Abstract-5"><a href="#Abstract-5" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li>本文提出了一种简单有效的训练神经网络的方法。我们的方法继承了知识精馏的思想，即将知识从深度或广泛的参考模型转移到浅层或狭窄的目标模型。</li><li>该方法利用这一思想来模拟参考估计量的预测，这些估计量比我们想要训练的网络更能抵抗过拟合。与以往几乎所有需要大量标记训练数据的知识提取工作不同，该方法只需要少量训练数据。</li><li>相反，我们引入了作为模型参数的一部分进行优化的伪训练示例。对多个基准数据集的实验结果表明，该方法优于目标模型的朴素训练和标准知识提取等所有基线。</li></ul><h3 id="Introduction-5"><a href="#Introduction-5" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li>深度学习过拟合的挑战</li><li><p>本文</p><ul><li>本文提出了一种利用少量有监督训练数据对神经网络进行训练的新方法。图1展示了我们所提出的模仿网络方法的基本思想。</li><li>在原理上，我们特别选择能够提供局部平滑预测的GPs作为参考模型。与以往几乎所有使用大量监督训练样本进行知识精化的工作不同，我们提出的方法只需要少量的监督训练样本进行知识转移。为了增加训练示例，我们引入了一些诱导点[30]，这些点是伪训练示例，可以帮助模型训练变得易于处理或简单得多。在原始的诱导点方法中，采用了可伸缩GP推理的诱导点和模型参数</li><li>然而，在我们提出的方法中，目标模型的参数被更新以减少训练损失，而伪训练实例被更新以增加训练损失。通过这样做，我们可以将伪训练示例移到当前目标模型没有得到良好训练的区域。我们还引入了保真度加权[6]，用于消除基于参考模型预测不确定性的有害伪训练实例</li></ul></li><li><p>主要贡献</p><ul><li><ol><li>提出了一种新的神经网络从无到有小概率训练的框架，这意味着既不需要额外的例子也不需要用大量的监督例子训练参考模型。</li></ol></li><li><ol start="2"><li>将诱导点的思想应用到神经网络的训练中，其优化方法与神经网络的模型参数几乎相同。</li></ol></li></ul></li></ul><p><em>XMind: ZEN - Trial Version</em></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Zero-Shot-Action-Recognition-with-Error-Correcting-Output-Codes&quot;&gt;&lt;a href=&quot;#Zero-Shot-Action-Recognition-with-Error-Correcting-Output
      
    
    </summary>
    
      <category term="Reading Notes of Paper" scheme="http://yoursite.com/categories/READING-NOTES-OF-PAPER/"/>
    
    
      <category term="SSL" scheme="http://yoursite.com/tags/SSL/"/>
    
  </entry>
  
  <entry>
    <title>Day One</title>
    <link href="http://yoursite.com/2017/11/25/Day-One/"/>
    <id>http://yoursite.com/2017/11/25/Day-One/</id>
    <published>2017-11-25T06:54:13.000Z</published>
    <updated>2017-11-25T07:51:54.260Z</updated>
    
    <content type="html"><![CDATA[<p>今天是11月25号，已经颓靡了很久的我终于搭建了一个可以访问的博客了，使用过阿里云的学生机，也使用过world press+老薛主机，两次都购买了一个月的使用期，配置过程中也遇到了很多问题，往往问题还没有解决的时候空间就要过期了。<br> 昨天尝试了使用hexo+github的免费静态网页搭建，虽然也遇到了坑，但是也花了一下午就搭建完成可以使用域名访问了，成就感真的，哇!终于有了自己的站点了。<br> 话说回来，一开始想用阿里云和老薛主机建站的目的，一方面是为了督促自己学习，一方面是为了通过服务器搭建网站帮助自己熟悉前后端的知识，可惜没有坚持下去。<br> 所以希望现在这个静态的免费站点能够支撑我记录自己的成长，不要荒废了我的时光和岁月！！！<br> 长久没有读书，写的文字也没有逻辑性，希望自己变成自己想要变成的样子！<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;--more--&gt;</span><br><span class="line"> 加油~~</span><br></pre></td></tr></table></figure></p><p>对话框么么？<br>~~~~</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天是11月25号，已经颓靡了很久的我终于搭建了一个可以访问的博客了，使用过阿里云的学生机，也使用过world press+老薛主机，两次都购买了一个月的使用期，配置过程中也遇到了很多问题，往往问题还没有解决的时候空间就要过期了。&lt;br&gt; 昨天尝试了使用hexo+githu
      
    
    </summary>
    
    
  </entry>
  
</feed>
